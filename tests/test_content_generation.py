#!/usr/bin/env python3
"""
test_content_generation.py

å†…å®¹ç”Ÿæˆæ¨¡å—çš„é›†æˆæµ‹è¯•
æµ‹è¯•å„ä¸ªç»„ä»¶çš„åŸºæœ¬åŠŸèƒ½
"""

import os
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))


def test_crawler():
    """æµ‹è¯•é‡å­ä½çˆ¬è™«"""
    print("\n" + "="*70)
    print("ğŸ§ª æµ‹è¯• 1: é‡å­ä½æ–°é—»çˆ¬è™«")
    print("="*70 + "\n")
    
    try:
        from generate.qbitai_crawler import QbitAICrawler
        
        crawler = QbitAICrawler()
        news_list = crawler.fetch_top_news(limit=3)
        
        assert len(news_list) > 0, "æœªæŠ“å–åˆ°ä»»ä½•æ–°é—»"
        assert 'title' in news_list[0], "æ–°é—»ç¼ºå°‘æ ‡é¢˜å­—æ®µ"
        assert 'url' in news_list[0], "æ–°é—»ç¼ºå°‘URLå­—æ®µ"
        
        print(f"âœ… æµ‹è¯•é€šè¿‡: æˆåŠŸæŠ“å– {len(news_list)} æ¡æ–°é—»")
        print(f"   ç¤ºä¾‹: {news_list[0]['title'][:50]}...")
        
        return True, news_list
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        return False, []


def test_reference_searcher(news_list):
    """æµ‹è¯•å‚è€ƒèµ„æ–™æœç´¢"""
    print("\n" + "="*70)
    print("ğŸ§ª æµ‹è¯• 2: å‚è€ƒèµ„æ–™æœç´¢")
    print("="*70 + "\n")
    
    if not news_list:
        print("âš ï¸ è·³è¿‡æµ‹è¯•: æ²¡æœ‰å¯ç”¨çš„æ–°é—»æ•°æ®")
        return False, None
    
    # æ£€æŸ¥APIå¯†é’¥
    api_key = os.environ.get("ZHIPUAI_API_KEY")
    if not api_key:
        print("âš ï¸ è·³è¿‡æµ‹è¯•: æœªè®¾ç½® ZHIPUAI_API_KEY ç¯å¢ƒå˜é‡")
        return False, None
    
    try:
        from generate.reference_searcher import ReferenceSearcher
        
        searcher = ReferenceSearcher()
        
        test_news = news_list[0]
        print(f"æµ‹è¯•è¯é¢˜: {test_news['title'][:50]}...")
        
        references = searcher.search_topic_references(
            topic=test_news['title'],
            original_summary=test_news.get('summary', ''),
            search_depth="quick"
        )
        
        assert references is not None, "æœç´¢è¿”å›ç©ºç»“æœ"
        assert 'topic' in references, "æœç´¢ç»“æœç¼ºå°‘topicå­—æ®µ"
        
        print(f"âœ… æµ‹è¯•é€šè¿‡: æˆåŠŸæœç´¢å‚è€ƒèµ„æ–™")
        print(f"   æŠ€æœ¯èƒŒæ™¯é•¿åº¦: {len(references.get('technical_background', ''))} å­—ç¬¦")
        print(f"   å…³é”®åˆ›æ–°ç‚¹: {len(references.get('key_innovations', []))} ä¸ª")
        
        return True, references
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False, None


def test_content_generator(news_list, references):
    """æµ‹è¯•å†…å®¹ç”Ÿæˆå™¨"""
    print("\n" + "="*70)
    print("ğŸ§ª æµ‹è¯• 3: å†…å®¹ç”Ÿæˆå™¨")
    print("="*70 + "\n")
    
    if not news_list or not references:
        print("âš ï¸ è·³è¿‡æµ‹è¯•: æ²¡æœ‰å¯ç”¨çš„æ–°é—»æˆ–å‚è€ƒèµ„æ–™")
        return False, None
    
    # æ£€æŸ¥APIå¯†é’¥
    api_key = os.environ.get("ZHIPUAI_API_KEY")
    if not api_key:
        print("âš ï¸ è·³è¿‡æµ‹è¯•: æœªè®¾ç½® ZHIPUAI_API_KEY ç¯å¢ƒå˜é‡")
        return False, None
    
    try:
        from generate.enhanced_content_generator import EnhancedContentGenerator
        
        generator = EnhancedContentGenerator()
        
        test_news = news_list[0]
        print(f"ç”Ÿæˆæ–‡ç« : {test_news['title'][:50]}...")
        
        # ä½¿ç”¨æµ‹è¯•è¾“å‡ºç›®å½•
        test_output_dir = "data/test_posts"
        Path(test_output_dir).mkdir(parents=True, exist_ok=True)
        
        article = generator.generate_article_from_news(
            news_item=test_news,
            references=references,
            style="qbitai",
            output_dir=test_output_dir
        )
        
        assert article is not None, "ç”Ÿæˆè¿”å›ç©ºç»“æœ"
        assert 'title' in article, "ç”Ÿæˆç»“æœç¼ºå°‘titleå­—æ®µ"
        assert 'content' in article, "ç”Ÿæˆç»“æœç¼ºå°‘contentå­—æ®µ"
        assert 'file_path' in article, "ç”Ÿæˆç»“æœç¼ºå°‘file_pathå­—æ®µ"
        
        # éªŒè¯æ–‡ä»¶å­˜åœ¨
        assert Path(article['file_path']).exists(), "ç”Ÿæˆçš„æ–‡ä»¶ä¸å­˜åœ¨"
        
        print(f"âœ… æµ‹è¯•é€šè¿‡: æˆåŠŸç”Ÿæˆæ–‡ç« ")
        print(f"   æ–°æ ‡é¢˜: {article['title'][:50]}...")
        print(f"   æ ‡ç­¾: {', '.join(article['tags'][:3])}")
        print(f"   æ–‡ä»¶: {article['file_path']}")
        
        return True, article
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False, None


def test_pipeline():
    """æµ‹è¯•å®Œæ•´æµæ°´çº¿"""
    print("\n" + "="*70)
    print("ğŸ§ª æµ‹è¯• 4: å®Œæ•´æµæ°´çº¿ï¼ˆè½»é‡çº§ï¼‰")
    print("="*70 + "\n")
    
    # æ£€æŸ¥APIå¯†é’¥
    api_key = os.environ.get("ZHIPUAI_API_KEY")
    if not api_key:
        print("âš ï¸ è·³è¿‡æµ‹è¯•: æœªè®¾ç½® ZHIPUAI_API_KEY ç¯å¢ƒå˜é‡")
        return False
    
    try:
        from generate.auto_content_pipeline import AutoContentPipeline
        
        pipeline = AutoContentPipeline(
            output_dir="data/test_posts",
            data_dir="data/test_generated"
        )
        
        print("è¿è¡Œè½»é‡çº§æµæ°´çº¿ï¼ˆ1æ¡æ–°é—» -> 1ç¯‡æ–‡ç« ï¼‰...")
        
        stats = pipeline.run(
            news_limit=3,
            article_limit=1,
            search_depth="quick",
            request_delay=1.0,
            save_intermediate=True
        )
        
        assert stats['crawled_news'] > 0, "æœªæŠ“å–åˆ°æ–°é—»"
        
        print(f"âœ… æµ‹è¯•é€šè¿‡: æµæ°´çº¿æ‰§è¡Œå®Œæˆ")
        print(f"   æŠ“å–æ–°é—»: {stats['crawled_news']} æ¡")
        print(f"   ç”Ÿæˆæ–‡ç« : {stats['generated_articles']} ç¯‡")
        
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("\n" + "="*80)
    print("ğŸš€ å†…å®¹ç”Ÿæˆæ¨¡å—é›†æˆæµ‹è¯•")
    print("="*80)
    
    results = []
    
    # æµ‹è¯•1: çˆ¬è™«
    success, news_list = test_crawler()
    results.append(("çˆ¬è™«æµ‹è¯•", success))
    
    # æµ‹è¯•2: æœç´¢
    success, references = test_reference_searcher(news_list)
    results.append(("æœç´¢æµ‹è¯•", success))
    
    # æµ‹è¯•3: ç”Ÿæˆå™¨
    success, article = test_content_generator(news_list, references)
    results.append(("ç”Ÿæˆå™¨æµ‹è¯•", success))
    
    # æµ‹è¯•4: æµæ°´çº¿
    success = test_pipeline()
    results.append(("æµæ°´çº¿æµ‹è¯•", success))
    
    # æ±‡æ€»ç»“æœ
    print("\n" + "="*80)
    print("ğŸ“Š æµ‹è¯•ç»“æœæ±‡æ€»")
    print("="*80 + "\n")
    
    passed = sum(1 for _, s in results if s)
    total = len(results)
    
    for name, success in results:
        status = "âœ… PASS" if success else "âŒ FAIL"
        print(f"  {status}  {name}")
    
    print(f"\næ€»è®¡: {passed}/{total} æµ‹è¯•é€šè¿‡")
    
    if passed == total:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        return 0
    else:
        print(f"\nâš ï¸ {total - passed} ä¸ªæµ‹è¯•å¤±è´¥")
        return 1


if __name__ == "__main__":
    sys.exit(main())
