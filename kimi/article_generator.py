#!/usr/bin/env python3
"""
æ–‡ç« ç”Ÿæˆå™¨æ¨¡å—
åŠŸèƒ½ï¼šåŸºäºæ•™ç¨‹ç« èŠ‚ï¼Œè¿›è¡Œæ·±åº¦ç ”ç©¶å¹¶ç”Ÿæˆå¸¦frontmatterçš„Markdownæ–‡ç« 
"""

import os
import json
import yaml
import httpx
import openai
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Optional


class FormulaChatClient:
    """Formula API å®¢æˆ·ç«¯ï¼ˆæ”¯æŒè”ç½‘æœç´¢ï¼‰"""
    
    def __init__(self, base_url: str, api_key: str):
        self.base_url = base_url
        self.api_key = api_key
        self.openai = openai.Client(base_url=base_url, api_key=api_key)
        self.httpx = httpx.Client(
            base_url=base_url,
            headers={"Authorization": f"Bearer {api_key}"},
            timeout=30.0,
        )
        self.model = "kimi-k2-thinking"
    
    def get_tools(self, formula_uri: str):
        """è·å–å·¥å…·å®šä¹‰"""
        response = self.httpx.get(f"/formulas/{formula_uri}/tools")
        response.raise_for_status()
        return response.json().get("tools", [])
    
    def call_tool(self, formula_uri: str, function: str, args: dict):
        """è°ƒç”¨å·¥å…·"""
        response = self.httpx.post(
            f"/formulas/{formula_uri}/fibers",
            json={"name": function, "arguments": json.dumps(args)},
        )
        response.raise_for_status()
        fiber = response.json()
        
        if fiber.get("status") == "succeeded":
            return fiber["context"].get("output") or fiber["context"].get("encrypted_output")
        
        if "error" in fiber:
            return f"Error: {fiber['error']}"
        return "Error: Unknown error"
    
    def close(self):
        self.httpx.close()


class ArticleGenerator:
    """æ–‡ç« ç”Ÿæˆå™¨ï¼šåŸºäºç« èŠ‚ç”Ÿæˆæ·±åº¦æŠ€æœ¯æ–‡ç« """
    
    def __init__(self, config_path: Optional[str] = None):
        """åˆå§‹åŒ–ç”Ÿæˆå™¨"""
        self.config = self._load_config(config_path)
        
        # åˆå§‹åŒ–å®¢æˆ·ç«¯
        base_url = os.getenv("MOONSHOT_BASE_URL", "https://api.moonshot.cn/v1")
        api_key = os.getenv("MOONSHOT_API_KEY")
        
        if not api_key:
            raise ValueError("MOONSHOT_API_KEY ç¯å¢ƒå˜é‡æœªè®¾ç½®")
        
        self.client = FormulaChatClient(base_url, api_key)
        self.client.model = self.config['article_generation']['model']
        
        # åŠ è½½æœç´¢å·¥å…·
        self.formula_uris = ["moonshot/web-search:latest", "moonshot/date:latest"]
        self.all_tools = []
        self.tool_to_uri = {}
        self._load_tools()
        
        # åŠ è½½æ•°æ®åº“
        self.curriculum_db_path = Path(__file__).parent / self.config['storage']['curriculum_db']
        self.history_db_path = Path(__file__).parent / self.config['storage']['generation_history']
        self.history_db_path.parent.mkdir(parents=True, exist_ok=True)
        
        self.curriculum_db = self._load_json(self.curriculum_db_path)
        self.history_db = self._load_json(self.history_db_path, default={"generations": []})
        
        # æœç´¢ç»“æœå­˜å‚¨
        self.search_results = []
        
        # åŠ è½½ä¸“å®¶æç¤ºè¯æ¨¡æ¿
        self.expert_prompt_template = self._load_expert_prompt()
    
    def _load_config(self, config_path: Optional[str] = None):
        """åŠ è½½é…ç½®"""
        if config_path is None:
            config_path = Path(__file__).parent / "tutorial_config.yaml"
        
        with open(config_path, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)
    
    def _load_json(self, path: Path, default: Optional[Dict] = None) -> Dict:
        """åŠ è½½JSON"""
        if path.exists():
            with open(path, 'r', encoding='utf-8') as f:
                return json.load(f)
        return default or {}
    
    def _save_json(self, path: Path, data: Dict):
        """ä¿å­˜JSON"""
        with open(path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
    
    def _load_tools(self):
        """åŠ è½½æœç´¢å·¥å…·"""
        print("\nğŸ”§ åŠ è½½æœç´¢å·¥å…·...")
        for uri in self.formula_uris:
            try:
                tools = self.client.get_tools(uri)
                for tool in tools:
                    func = tool.get("function")
                    if func:
                        func_name = func.get("name")
                        if func_name:
                            self.tool_to_uri[func_name] = uri
                            self.all_tools.append(tool)
                            print(f"   âœ“ {func_name}")
            except Exception as e:
                print(f"   âœ— åŠ è½½ {uri} å¤±è´¥: {e}")
        print(f"   å…±åŠ è½½ {len(self.all_tools)} ä¸ªå·¥å…·\n")
    
    def _load_expert_prompt(self):
        """åŠ è½½ä¸“å®¶æç¤ºè¯æ¨¡æ¿"""
        prompt_path = Path(__file__).parent / "prompts" / "expert_narrator.txt"
        if prompt_path.exists():
            with open(prompt_path, 'r', encoding='utf-8') as f:
                return f.read()
        return self._default_expert_prompt()
    
    def _default_expert_prompt(self):
        """é»˜è®¤ä¸“å®¶æç¤ºè¯"""
        return """ä½ æ˜¯ä¸€ä½åœ¨ AI/å¤§æ¨¡å‹é¢†åŸŸæœ‰ 15 å¹´ç ”ç©¶ç»éªŒçš„èµ„æ·±ä¸“å®¶ã€‚

åŸºäºä»¥ä¸‹ä¿¡æ¯ï¼š
{search_results}

è¯·æ·±å…¥è®²è§£ï¼š{topic}

ç« èŠ‚å¤§çº²ï¼š
{content_outline}

å­¦ä¹ ç›®æ ‡ï¼š
{learning_objectives}

è¦æ±‚ï¼š
1. æ·±å…¥æµ…å‡ºï¼Œé€šä¿—æ˜“æ‡‚
2. ä½¿ç”¨æ¯”å–»å’Œå®ä¾‹
3. ç»“æ„æ¸…æ™°ï¼Œé€»è¾‘æµç•…
4. Markdown æ ¼å¼
5. åŒ…å«ä»£ç ç¤ºä¾‹ï¼ˆå¦‚é€‚ç”¨ï¼‰

å¼€å§‹ä½ çš„è®²è§£ï¼š"""
    
    def generate_article(
        self, 
        topic_name: str, 
        chapter_number: int,
        verbose: bool = True
    ) -> Dict:
        """
        ç”ŸæˆæŒ‡å®šç« èŠ‚çš„æ–‡ç« 
        
        Args:
            topic_name: ä¸»é¢˜åç§°
            chapter_number: ç« èŠ‚ç¼–å·
            verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†è¿‡ç¨‹
            
        Returns:
            åŒ…å«æ–‡ç« å†…å®¹å’Œå…ƒæ•°æ®çš„å­—å…¸
        """
        if verbose:
            print(f"\n{'='*70}")
            print(f"âœï¸  ç”Ÿæˆæ–‡ç« ")
            print(f"   ä¸»é¢˜: {topic_name}")
            print(f"   ç« èŠ‚: ç¬¬{chapter_number}ç« ")
            print(f"{'='*70}\n")
        
        # è·å–æ•™ç¨‹å¤§çº²
        curriculum = self._get_curriculum(topic_name)
        if not curriculum:
            raise ValueError(f"æœªæ‰¾åˆ°ä¸»é¢˜ '{topic_name}' çš„æ•™ç¨‹å¤§çº²")
        
        # è·å–ç« èŠ‚ä¿¡æ¯
        chapter = self._get_chapter(curriculum, chapter_number)
        if not chapter:
            raise ValueError(f"æœªæ‰¾åˆ°ç¬¬ {chapter_number} ç« ")
        
        if verbose:
            print(f"ğŸ“– ç« èŠ‚ä¿¡æ¯:")
            print(f"   æ ‡é¢˜: {chapter['title']}")
            print(f"   éš¾åº¦: {chapter.get('difficulty', 'N/A')}")
            print(f"   é¢„è®¡æ—¶é—´: {chapter.get('estimated_reading_time', 'N/A')}åˆ†é’Ÿ\n")
        
        # ç¬¬ä¸€é˜¶æ®µï¼šä¿¡æ¯æ”¶é›†
        self.search_results = []
        search_topic = f"{topic_name} - {chapter['title']}"
        
        if verbose:
            print("ã€é˜¶æ®µ 1/2ã€‘ğŸ“š ä¿¡æ¯æ”¶é›†")
            print("-" * 70)
        
        self._research_phase(search_topic, chapter, verbose)
        
        # ç¬¬äºŒé˜¶æ®µï¼šæ–‡ç« å†™ä½œ
        if verbose:
            print(f"\n{'='*70}")
            print("ã€é˜¶æ®µ 2/2ã€‘âœï¸  æ–‡ç« å†™ä½œ")
            print("-" * 70)
        
        article_content = self._writing_phase(
            topic_name, 
            chapter, 
            curriculum.get('curriculum_name', topic_name),
            verbose
        )
        
        # ç”Ÿæˆfrontmatter
        frontmatter = self._generate_frontmatter(
            topic_name, 
            chapter, 
            curriculum
        )
        
        # ç»„åˆå®Œæ•´æ–‡ç« 
        full_content = self._compose_article(frontmatter, article_content)
        
        # ä¿å­˜æ–‡ç« 
        output_file = self._save_article(
            topic_name,
            chapter_number,
            chapter['title'],
            full_content
        )
        
        # è®°å½•ç”Ÿæˆå†å²
        generation_record = {
            "topic": topic_name,
            "chapter_number": chapter_number,
            "chapter_title": chapter['title'],
            "generated_at": datetime.now().isoformat(),
            "output_file": str(output_file),
            "word_count": len(article_content),
            "search_count": len(self.search_results)
        }
        
        self.history_db["generations"].append(generation_record)
        self._save_json(self.history_db_path, self.history_db)
        
        if verbose:
            print(f"\n{'='*70}")
            print(f"âœ… æ–‡ç« ç”Ÿæˆå®Œæˆï¼")
            print(f"   æ–‡ä»¶: {output_file}")
            print(f"   å­—æ•°: {len(article_content):,}")
            print(f"   æœç´¢æ¬¡æ•°: {len(self.search_results)}")
            print(f"{'='*70}\n")
        
        return {
            "content": full_content,
            "frontmatter": frontmatter,
            "output_file": str(output_file),
            "metadata": generation_record
        }
    
    def _research_phase(self, topic: str, chapter: Dict, verbose: bool):
        """ä¿¡æ¯æ”¶é›†é˜¶æ®µ"""
        max_rounds = self.config['article_generation']['max_search_rounds']
        
        # æ„å»ºç ”ç©¶æç¤ºè¯
        research_prompt = self._build_research_prompt(topic, chapter)
        
        messages = [
            {
                "role": "system",
                "content": """ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„æŠ€æœ¯ç ”ç©¶å‘˜ï¼Œè´Ÿè´£ä¸ºæŠ€æœ¯æ–‡ç« æ”¶é›†å…¨é¢ã€æƒå¨çš„èµ„æ–™ã€‚

ç ”ç©¶ç­–ç•¥ï¼š
- ä¼˜å…ˆæœç´¢æƒå¨æ¥æºï¼šé¡¶ä¼šè®ºæ–‡ã€å®˜æ–¹æ–‡æ¡£ã€çŸ¥åå›¢é˜Ÿçš„æŠ€æœ¯åšå®¢
- æ³¨é‡æ—¶æ•ˆæ€§ï¼šå¯»æ‰¾æœ€æ–°çš„ç ”ç©¶è¿›å±•å’Œå®é™…åº”ç”¨æ¡ˆä¾‹
- å¤šè§’åº¦è¦†ç›–ï¼šç†è®ºåŸºç¡€ã€æŠ€æœ¯å®ç°ã€åº”ç”¨æ¡ˆä¾‹ã€å¯¹æ¯”åˆ†æ
- å…³æ³¨ç»†èŠ‚ï¼šç®—æ³•æµç¨‹ã€ä»£ç å®ç°ã€æ€§èƒ½æ•°æ®ã€å®é™…æ•ˆæœ
- é¿å…å†—ä½™ï¼šä¸é‡å¤æœç´¢å·²è¦†ç›–çš„å†…å®¹

ä¿¡æ¯æ”¶é›†æ ‡å‡†ï¼š
âœ“ æ¦‚å¿µå®šä¹‰æ¸…æ™°
âœ“ åŸç†è®²è§£å……åˆ†
âœ“ å®ç°ç»†èŠ‚å…·ä½“
âœ“ æ¡ˆä¾‹çœŸå®å¯é 
âœ“ æ•°æ®å‡†ç¡®æƒå¨

å½“ä½ è®¤ä¸ºå·²æ”¶é›†åˆ°è¶³å¤Ÿå…¨é¢çš„ä¿¡æ¯æ—¶ï¼Œå›å¤"èµ„æ–™æ”¶é›†å®Œæˆ"ã€‚"""
            },
            {
                "role": "user",
                "content": research_prompt
            }
        ]
        
        for round_num in range(max_rounds):
            if verbose:
                print(f"\n>>> ç¬¬ {round_num + 1}/{max_rounds} è½®")
            
            try:
                completion = self.client.openai.chat.completions.create(
                    model=self.client.model,
                    messages=messages,
                    max_tokens=self.config['article_generation']['max_tokens'],
                    tools=self.all_tools,
                    temperature=self.config['article_generation']['search_temperature'],
                )
            except Exception as e:
                print(f"âœ— APIè°ƒç”¨å¤±è´¥: {e}")
                break
            
            message = completion.choices[0].message
            messages.append(message)
            
            # å¤„ç†å·¥å…·è°ƒç”¨
            if not message.tool_calls:
                if message.content and any(kw in message.content for kw in 
                    ["ä¿¡æ¯æ”¶é›†å®Œæˆ", "æ”¶é›†å®Œæ¯•", "ç ”ç©¶å®Œæˆ", "èµ„æ–™æ”¶é›†å®Œæˆ", "æœç´¢å®Œæˆ", 
                     "å·²æ”¶é›†", "è¶³å¤Ÿ", "å®Œæˆæ”¶é›†"]):
                    if verbose:
                        print("\nâœ“ èµ„æ–™æ”¶é›†å®Œæˆ")
                    break
                continue
            
            if verbose:
                print(f"ğŸ” è°ƒç”¨ {len(message.tool_calls)} ä¸ªå·¥å…·")
            
            for tool_call in message.tool_calls:
                func_name = tool_call.function.name
                args = json.loads(tool_call.function.arguments)
                
                if verbose:
                    query = args.get('query', str(args)[:50])
                    print(f"   æœç´¢: {query}")
                
                formula_uri = self.tool_to_uri.get(func_name)
                if not formula_uri:
                    continue
                
                try:
                    result = self.client.call_tool(formula_uri, func_name, args)
                    
                    if func_name == "web_search":
                        self.search_results.append({
                            "query": args.get("query", ""),
                            "result": result,
                            "timestamp": datetime.now().isoformat()
                        })
                    
                    messages.append({
                        "role": "tool",
                        "tool_call_id": tool_call.id,
                        "name": func_name,
                        "content": result
                    })
                except Exception as e:
                    if verbose:
                        print(f"   âœ— å·¥å…·è°ƒç”¨å¤±è´¥: {e}")
    
    def _writing_phase(
        self, 
        topic_name: str, 
        chapter: Dict, 
        series_name: str,
        verbose: bool
    ) -> str:
        """æ–‡ç« å†™ä½œé˜¶æ®µ"""
        if verbose:
            print(f"\nğŸ“Š å·²æ”¶é›† {len(self.search_results)} æ¡æœç´¢ç»“æœ")
            print("ğŸ¯ æ­£åœ¨ç”Ÿæˆæ–‡ç« ...\n")
        
        # æ•´ç†æœç´¢ç»“æœ
        formatted_results = self._format_search_results()
        
        # æ„å»ºå­¦ä¹ ç›®æ ‡ï¼ˆæ›´è‡ªç„¶çš„è¡¨è¿°ï¼‰
        learning_objectives_text = "\n".join([f"â€¢ {obj}" for obj in chapter.get('learning_objectives', [])])
        
        # æ„å»ºå†…å®¹è¦ç‚¹ï¼ˆæ›´è‡ªç„¶çš„è¡¨è¿°ï¼‰
        content_outline_text = "\n".join([f"{i}. {item}" for i, item in enumerate(chapter.get('content_outline', []), 1)])
        
        # æ„å»ºå†™ä½œæç¤ºè¯
        writing_prompt = self.expert_prompt_template.format(
            topic=chapter['title'],
            search_results=formatted_results,
            content_outline=content_outline_text,
            learning_objectives=learning_objectives_text
        )
        
        try:
            response = self.client.openai.chat.completions.create(
                model=self.client.model,
                messages=[{"role": "user", "content": writing_prompt}],
                max_tokens=self.config['article_generation']['max_tokens'],
                temperature=self.config['article_generation']['writing_temperature'],
            )
            
            content = response.choices[0].message.content
            
            if verbose:
                print("âœ“ æ–‡ç« ç”Ÿæˆå®Œæˆ")
            
            return content
            
        except Exception as e:
            print(f"âœ— æ–‡ç« ç”Ÿæˆå¤±è´¥: {e}")
            raise
    
    def _format_search_results(self) -> str:
        """æ ¼å¼åŒ–æœç´¢ç»“æœ"""
        if not self.search_results:
            return "ï¼ˆæš‚æ— å‚è€ƒèµ„æ–™ï¼‰"
        
        formatted = []
        for i, item in enumerate(self.search_results, 1):
            query = item['query']
            result = item['result']
            
            # æ›´è‡ªç„¶çš„æ ¼å¼ï¼Œä¾¿äº AI ç†è§£å’Œå¼•ç”¨
            formatted.append(f"""
## å‚è€ƒèµ„æ–™ {i}

**æœç´¢ä¸»é¢˜**ï¼š{query}

**ç›¸å…³ä¿¡æ¯**ï¼š
{result}

---
""")
        
        return "\n".join(formatted)
    
    def _build_research_prompt(self, topic: str, chapter: Dict) -> str:
        """æ„å»ºç ”ç©¶æç¤ºè¯"""
        # æ ¼å¼åŒ–å­¦ä¹ ç›®æ ‡
        objectives = chapter.get('learning_objectives', [])
        objectives_text = "\n".join(f"  â€¢ {obj}" for obj in objectives) if objectives else "  æš‚æ— "
        
        # æ ¼å¼åŒ–æ ¸å¿ƒæ¦‚å¿µ
        concepts = chapter.get('key_concepts', [])
        concepts_text = "ã€".join(concepts) if concepts else "æš‚æ— "
        
        # æ ¼å¼åŒ–å†…å®¹å¤§çº²
        outline = chapter.get('content_outline', [])
        outline_text = "\n".join(f"  {i}. {item}" for i, item in enumerate(outline, 1)) if outline else "  æš‚æ— "
        
        return f"""æˆ‘éœ€è¦ä¸ºä»¥ä¸‹ä¸»é¢˜æ’°å†™ä¸€ç¯‡æŠ€æœ¯æ–‡ç« ï¼Œè¯·å¸®æˆ‘æ”¶é›†å…¨é¢ã€æƒå¨çš„èµ„æ–™ã€‚

ğŸ“– æ–‡ç« ä¸»é¢˜ï¼š
{chapter.get('title', topic)}

ğŸ¯ å­¦ä¹ ç›®æ ‡ï¼š
{objectives_text}

ğŸ”‘ æ ¸å¿ƒæ¦‚å¿µï¼š
{concepts_text}

ğŸ“‹ å†…å®¹è¦ç‚¹ï¼š
{outline_text}

è¯·æŒ‰ä»¥ä¸‹ç»´åº¦æ”¶é›†ä¿¡æ¯ï¼š
1. æ¦‚å¿µå®šä¹‰å’Œç†è®ºåŸºç¡€
2. æŠ€æœ¯åŸç†å’Œå®ç°æ–¹æ³•
3. å®é™…åº”ç”¨æ¡ˆä¾‹ï¼ˆæœ€å¥½æ˜¯çŸ¥åäº§å“ï¼‰
4. ä»£ç ç¤ºä¾‹å’Œæœ€ä½³å®è·µ
5. æ€§èƒ½æ•°æ®å’Œæ•ˆæœå¯¹æ¯”
6. ç ”ç©¶è¿›å±•å’Œæœªæ¥è¶‹åŠ¿

æ³¨æ„ï¼š
- ä¼˜å…ˆæœç´¢æƒå¨æ¥æºï¼ˆè®ºæ–‡ã€å®˜æ–¹æ–‡æ¡£ã€æŠ€æœ¯åšå®¢ï¼‰
- å…³æ³¨ 2023-2025 å¹´çš„æœ€æ–°è¿›å±•
- æ”¶é›†å…·ä½“çš„æ•°æ®å’Œæ¡ˆä¾‹ï¼Œè€Œéæ³›æ³›è€Œè°ˆ
- é¿å…é‡å¤æœç´¢å·²çŸ¥å†…å®¹

å¼€å§‹æœç´¢å§ï¼"""
    
    def _generate_frontmatter(
        self, 
        topic_name: str, 
        chapter: Dict, 
        curriculum: Dict
    ) -> Dict:
        """ç”Ÿæˆfrontmatter"""
        # æå–åˆ†ç±»
        categories = ["AI", "æ·±åº¦å­¦ä¹ "]
        
        # æ ¹æ®ä¸»é¢˜æ·»åŠ ç‰¹å®šåˆ†ç±»
        topic_lower = topic_name.lower()
        if any(kw in topic_lower for kw in ["transformer", "æ³¨æ„åŠ›", "attention"]):
            categories.append("Transformer")
        if any(kw in topic_lower for kw in ["vla", "vision", "language", "action"]):
            categories.append("å¤šæ¨¡æ€")
        if any(kw in topic_lower for kw in ["å¼ºåŒ–å­¦ä¹ ", "reinforcement", "rl"]):
            categories.append("å¼ºåŒ–å­¦ä¹ ")
        if any(kw in topic_lower for kw in ["agent", "æ™ºèƒ½ä½“"]):
            categories.append("AI Agent")
        
        # ä»ç« èŠ‚æå–æ ‡ç­¾
        tags = []
        
        # ä»æ ¸å¿ƒæ¦‚å¿µæå–ï¼ˆé™åˆ¶æ•°é‡ï¼‰
        key_concepts = chapter.get('key_concepts', [])[:5]
        tags.extend(key_concepts)
        
        # å»é‡å’Œæ¸…ç†
        tags = list(dict.fromkeys([t.strip() for t in tags if t.strip()]))
        categories = list(dict.fromkeys(categories))
        
        return {
            "title": chapter['title'],
            "date": datetime.now().strftime("%Y-%m-%d"),
            "author": "AIæŠ€æœ¯ä¸“å®¶",
            "categories": categories,
            "tags": tags,
            "description": chapter.get('subtitle', chapter['title'])[:150],
            "series": curriculum.get('curriculum_name', topic_name),
            "chapter": chapter.get('chapter_number', 1),
            "difficulty": chapter.get('difficulty', 'intermediate'),
            "estimated_reading_time": f"{chapter.get('estimated_reading_time', 15)}åˆ†é’Ÿ"
        }
    
    def _compose_article(self, frontmatter: Dict, content: str) -> str:
        """ç»„åˆå®Œæ•´æ–‡ç« """
        # æ¸…ç†å†…å®¹ï¼šå¦‚æœæ¨¡å‹ç”Ÿæˆäº† frontmatterï¼Œéœ€è¦ç§»é™¤
        content = content.strip()
        
        # æ£€æµ‹å¹¶ç§»é™¤å†…å®¹å¼€å¤´çš„ frontmatter
        if content.startswith("---"):
            # æ‰¾åˆ°ç¬¬äºŒä¸ª --- çš„ä½ç½®
            second_delimiter = content.find("---", 3)
            if second_delimiter != -1:
                # ç§»é™¤æ•´ä¸ª frontmatter å—
                content = content[second_delimiter + 3:].strip()
                print("âš ï¸  æ£€æµ‹åˆ°æ¨¡å‹ç”Ÿæˆäº† frontmatterï¼Œå·²è‡ªåŠ¨ç§»é™¤")
        
        # ç”Ÿæˆæˆ‘ä»¬è‡ªå·±çš„ YAML frontmatter
        fm_lines = ["---"]
        for key, value in frontmatter.items():
            if isinstance(value, list):
                fm_lines.append(f"{key}:")
                for item in value:
                    fm_lines.append(f"  - {item}")
            else:
                fm_lines.append(f"{key}: {value}")
        fm_lines.append("---")
        fm_lines.append("")
        
        return "\n".join(fm_lines) + "\n" + content
    
    def _save_article(
        self, 
        topic_name: str, 
        chapter_number: int,
        chapter_title: str,
        content: str
    ) -> Path:
        """ä¿å­˜æ–‡ç« åˆ°æ–‡ä»¶"""
        output_dir = Path(__file__).parent / self.config['storage']['articles_output']
        output_dir = output_dir.resolve()
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # ç”Ÿæˆæ–‡ä»¶åï¼šç›´æ¥ä½¿ç”¨ç« èŠ‚æ ‡é¢˜ä½œä¸ºæ–‡ä»¶åï¼ˆé€‚åˆä½œä¸ºåšå®¢æ ‡é¢˜ï¼‰
        # æ¸…ç†æ–‡ä»¶åä¸­çš„éæ³•å­—ç¬¦ï¼Œä½†ä¿ç•™ä¸­æ–‡ã€è‹±æ–‡ã€æ•°å­—å’Œå¸¸ç”¨åˆ†éš”ç¬¦
        import re
        
        # ä¿ç•™ä¸­æ–‡ã€è‹±æ–‡ã€æ•°å­—ã€ç©ºæ ¼ã€è¿å­—ç¬¦å’Œä¸‹åˆ’çº¿
        safe_title = re.sub(r'[^\w\s\-\u4e00-\u9fff]', '', chapter_title)
        # å°†å¤šä¸ªç©ºæ ¼æ›¿æ¢ä¸ºå•ä¸ªä¸‹åˆ’çº¿
        safe_title = re.sub(r'\s+', '_', safe_title.strip())
        # é™åˆ¶é•¿åº¦
        safe_title = safe_title[:100]
        
        # å¦‚æœæ ‡é¢˜ä¸ºç©ºï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ
        if not safe_title:
            safe_title = f"{topic_name}_Chapter_{chapter_number}"
            safe_title = re.sub(r'[^\w\s\-\u4e00-\u9fff]', '', safe_title)
            safe_title = re.sub(r'\s+', '_', safe_title.strip())
        
        filename = f"{safe_title}.md"
        output_path = output_dir / filename
        
        # å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œæ·»åŠ æ—¶é—´æˆ³åç¼€
        if output_path.exists():
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"{safe_title}_{timestamp}.md"
            output_path = output_dir / filename
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(content)
        
        return output_path
    
    def _get_curriculum(self, topic_name: str) -> Optional[Dict]:
        """è·å–æ•™ç¨‹å¤§çº²ï¼ˆæ”¯æŒæ¨¡ç³ŠåŒ¹é…ï¼‰"""
        import re
        
        def normalize_name(name: str) -> str:
            """è§„èŒƒåŒ–ä¸»é¢˜åç§°ï¼šç§»é™¤æ‰€æœ‰åˆ†éš”ç¬¦ã€ç»Ÿä¸€ä¸ºå°å†™"""
            name = name.lower()
            # ç§»é™¤æ‰€æœ‰æ‹¬å·ã€è¿å­—ç¬¦ã€ä¸‹åˆ’çº¿ã€ç©ºæ ¼
            name = re.sub(r'[ï¼ˆï¼‰()_\-\s]+', '', name)
            return name
        
        normalized_search = normalize_name(topic_name)
        
        # é¦–å…ˆå°è¯•ç²¾ç¡®åŒ¹é…
        for curr in self.curriculum_db.get("curriculums", []):
            curr_topic = curr.get("main_topic", "")
            if normalize_name(curr_topic) == normalized_search:
                return curr
        
        # å¦‚æœç²¾ç¡®åŒ¹é…å¤±è´¥ï¼Œå°è¯•éƒ¨åˆ†åŒ¹é…
        for curr in self.curriculum_db.get("curriculums", []):
            curr_topic = normalize_name(curr.get("main_topic", ""))
            # æ£€æŸ¥æ˜¯å¦åŒ…å«æœç´¢è¯çš„ä¸»è¦éƒ¨åˆ†
            if normalized_search in curr_topic or curr_topic in normalized_search:
                return curr
        
        return None
    
    def _get_chapter(self, curriculum: Dict, chapter_number: int) -> Optional[Dict]:
        """è·å–æŒ‡å®šç« èŠ‚"""
        for chapter in curriculum.get("chapters", []):
            if chapter.get("chapter_number") == chapter_number:
                return chapter
        return None
    
    def generate_series(
        self, 
        topic_name: str, 
        chapter_range: Optional[tuple] = None,
        verbose: bool = True
    ):
        """ç”Ÿæˆç³»åˆ—æ•™ç¨‹"""
        curriculum = self._get_curriculum(topic_name)
        if not curriculum:
            raise ValueError(f"æœªæ‰¾åˆ°ä¸»é¢˜ '{topic_name}' çš„æ•™ç¨‹å¤§çº²")
        
        chapters = curriculum.get("chapters", [])
        total = len(chapters)
        
        if chapter_range:
            start, end = chapter_range
            chapters = [ch for ch in chapters if start <= ch.get('chapter_number', 0) <= end]
        
        print(f"\n{'='*70}")
        print(f"ğŸ“š æ‰¹é‡ç”Ÿæˆæ•™ç¨‹ç³»åˆ—")
        print(f"   ä¸»é¢˜: {topic_name}")
        print(f"   ç« èŠ‚: {len(chapters)}/{total}")
        print(f"{'='*70}\n")
        
        results = []
        for i, chapter in enumerate(chapters, 1):
            ch_num = chapter.get('chapter_number', i)
            print(f"[{i}/{len(chapters)}] ç”Ÿæˆç¬¬{ch_num}ç« : {chapter['title']}")
            print("-" * 70)
            
            try:
                result = self.generate_article(topic_name, ch_num, verbose=verbose)
                results.append(result)
            except Exception as e:
                print(f"âœ— ç”Ÿæˆå¤±è´¥: {e}\n")
                continue
            
            # é¿å…è¯·æ±‚è¿‡å¿«
            if i < len(chapters):
                import time
                print("\nâ³ ç­‰å¾… 5 ç§’...\n")
                time.sleep(5)
        
        print(f"{'='*70}")
        print(f"âœ… ç³»åˆ—ç”Ÿæˆå®Œæˆ - æˆåŠŸ {len(results)}/{len(chapters)}")
        print(f"{'='*70}\n")
        
        return results
    
    def close(self):
        """å…³é—­å®¢æˆ·ç«¯"""
        self.client.close()


def main():
    """æµ‹è¯•æ–‡ç« ç”Ÿæˆå™¨"""
    import argparse
    
    parser = argparse.ArgumentParser(description='æ–‡ç« ç”Ÿæˆå™¨')
    parser.add_argument('-t', '--topic', type=str, required=True, help='ä¸»é¢˜åç§°')
    parser.add_argument('-n', '--chapter', type=int, help='ç« èŠ‚ç¼–å·')
    parser.add_argument('-r', '--range', type=str, help='ç« èŠ‚èŒƒå›´ï¼Œå¦‚ 1-5')
    parser.add_argument('-a', '--all', action='store_true', help='ç”Ÿæˆæ‰€æœ‰ç« èŠ‚')
    parser.add_argument('-c', '--config', type=str, help='é…ç½®æ–‡ä»¶è·¯å¾„')
    
    args = parser.parse_args()
    
    try:
        generator = ArticleGenerator(config_path=args.config)
        
        if args.all:
            generator.generate_series(args.topic, verbose=True)
        elif args.range:
            start, end = map(int, args.range.split('-'))
            generator.generate_series(args.topic, chapter_range=(start, end), verbose=True)
        elif args.chapter:
            generator.generate_article(args.topic, args.chapter, verbose=True)
        else:
            print("è¯·æŒ‡å®šç« èŠ‚ç¼–å· (-n) æˆ–èŒƒå›´ (-r) æˆ–å…¨éƒ¨ (-a)")
    
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
    finally:
        if 'generator' in locals():
            generator.close()


if __name__ == "__main__":
    main()
