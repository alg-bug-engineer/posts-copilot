#!/usr/bin/env python3
"""
æ•™ç¨‹å¤§çº²ç”Ÿæˆå™¨
åŠŸèƒ½ï¼šåŸºäºæ¢ç´¢çš„å­ä¸»é¢˜ï¼Œç”Ÿæˆæœ‰é€»è¾‘ã€å¾ªåºæ¸è¿›çš„æ•™ç¨‹ä½“ç³»
"""

import os
import json
import yaml
import openai
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Optional


class CurriculumGenerator:
    """æ•™ç¨‹å¤§çº²ç”Ÿæˆå™¨ï¼šç»„ç»‡å­ä¸»é¢˜æˆä¸ºå¾ªåºæ¸è¿›çš„æ•™ç¨‹ä½“ç³»"""
    
    def __init__(self, config_path: Optional[str] = None):
        """åˆå§‹åŒ–ç”Ÿæˆå™¨"""
        self.config = self._load_config(config_path)
        
        # åˆå§‹åŒ– API å®¢æˆ·ç«¯
        base_url = os.getenv("MOONSHOT_BASE_URL", "https://api.moonshot.cn/v1")
        api_key = os.getenv("MOONSHOT_API_KEY")
        
        if not api_key:
            raise ValueError("MOONSHOT_API_KEY ç¯å¢ƒå˜é‡æœªè®¾ç½®")
        
        self.client = openai.Client(base_url=base_url, api_key=api_key)
        self.model = self.config['article_generation']['model']
        
        # åŠ è½½æ•°æ®åº“
        self.topics_db_path = Path(__file__).parent / self.config['storage']['topics_db']
        self.curriculum_db_path = Path(__file__).parent / self.config['storage']['curriculum_db']
        self.curriculum_db_path.parent.mkdir(parents=True, exist_ok=True)
        
        self.topics_db = self._load_json(self.topics_db_path)
        self.curriculum_db = self._load_json(self.curriculum_db_path, default={"curriculums": []})
    
    def _load_config(self, config_path: Optional[str] = None):
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        if config_path is None:
            config_path = Path(__file__).parent / "tutorial_config.yaml"
        
        with open(config_path, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)
    
    def _load_json(self, path: Path, default: Optional[Dict] = None) -> Dict:
        """åŠ è½½JSONæ–‡ä»¶"""
        if path.exists():
            with open(path, 'r', encoding='utf-8') as f:
                return json.load(f)
        return default or {}
    
    def _save_json(self, path: Path, data: Dict):
        """ä¿å­˜JSONæ–‡ä»¶"""
        with open(path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
    
    def generate_curriculum(self, topic_name: str, verbose: bool = True) -> Dict:
        """
        ä¸ºæŒ‡å®šä¸»é¢˜ç”Ÿæˆæ•™ç¨‹å¤§çº²
        
        Args:
            topic_name: ä¸»é¢˜åç§°
            verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†è¿‡ç¨‹
            
        Returns:
            æ•™ç¨‹å¤§çº²æ•°æ®
        """
        if verbose:
            print(f"\n{'='*70}")
            print(f"ğŸ“– ç”Ÿæˆæ•™ç¨‹å¤§çº²: {topic_name}")
            print(f"{'='*70}\n")
        
        # ä»ä¸»é¢˜åº“ä¸­æŸ¥æ‰¾ä¸»é¢˜æ•°æ®
        topic_data = self._find_topic(topic_name)
        if not topic_data:
            raise ValueError(f"ä¸»é¢˜ '{topic_name}' æœªæ‰¾åˆ°ï¼Œè¯·å…ˆä½¿ç”¨ topic_explorer æ¢ç´¢è¯¥ä¸»é¢˜")
        
        if verbose:
            print(f"âœ“ æ‰¾åˆ°ä¸»é¢˜æ•°æ®")
            print(f"  å­ä¸»é¢˜æ•°é‡: {len(topic_data.get('subtopics', []))}")
            print(f"  éš¾åº¦çº§åˆ«: {topic_data.get('difficulty_level', 'N/A')}\n")
        
        # æ„å»ºå¤§çº²ç”Ÿæˆæç¤ºè¯
        prompt = self._build_curriculum_prompt(topic_data)
        
        if verbose:
            print("ğŸ¯ æ­£åœ¨ç”Ÿæˆå¾ªåºæ¸è¿›çš„æ•™ç¨‹å¤§çº²...\n")
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": """ä½ æ˜¯ä¸€ä½èµ„æ·±çš„æŠ€æœ¯æ•™è‚²ä¸“å®¶å’Œè¯¾ç¨‹æ¶æ„å¸ˆï¼Œæ“…é•¿è®¾è®¡ç³»ç»ŸåŒ–ã€å¾ªåºæ¸è¿›çš„å­¦ä¹ è·¯å¾„ã€‚

ä½ çš„è®¾è®¡åŸåˆ™ï¼š
1. çŸ¥è¯†é€’è¿›ï¼šä»åŸºç¡€æ¦‚å¿µåˆ°é«˜çº§åº”ç”¨ï¼Œå±‚å±‚æ·±å…¥
2. é€»è¾‘è¿è´¯ï¼šå‰åç« èŠ‚ç´§å¯†å…³è”ï¼Œå½¢æˆå®Œæ•´çŸ¥è¯†ä½“ç³»
3. ç›®æ ‡æ˜ç¡®ï¼šæ¯ç« éƒ½æœ‰æ¸…æ™°çš„å­¦ä¹ ç›®æ ‡å’Œå®é™…äº§å‡º
4. éš¾åº¦åˆç†ï¼šç¬¦åˆè®¤çŸ¥è§„å¾‹ï¼Œé¿å…çªå˜å’Œè·³è·ƒ
5. å®æˆ˜å¯¼å‘ï¼šæ³¨é‡ç†è®ºä¸å®è·µç»“åˆ

ç« èŠ‚æ ‡é¢˜è¦æ±‚ï¼š
- å‡†ç¡®åæ˜ æ ¸å¿ƒå†…å®¹
- é¿å…ç”Ÿç¡¬çš„"ç¬¬Xç« "æ ¼å¼
- ä½¿ç”¨å¸å¼•äººçš„è¡¨è¿°
- ç¤ºä¾‹ï¼š
  âœ“ "æ³¨æ„åŠ›æœºåˆ¶çš„æœ¬è´¨ä¸è®¡ç®—åŸç†"
  âœ“ "ä» RNN åˆ° Transformer çš„æ¼”è¿›å†ç¨‹"
  âœ— "ç¬¬1ç«  åŸºç¡€çŸ¥è¯†"
  âœ— "Transformer ä»‹ç»"

è¾“å‡ºæ ¼å¼å¿…é¡»æ˜¯çº¯ JSONï¼š
{
  "curriculum_name": "æ•™ç¨‹ç³»åˆ—åç§°",
  "main_topic": "ä¸»é¢˜åç§°",
  "description": "æ•™ç¨‹ç³»åˆ—ç®€ä»‹",
  "target_audience": "ç›®æ ‡è¯»è€…",
  "prerequisites": ["å‰ç½®è¦æ±‚"],
  "total_chapters": ç« èŠ‚æ€»æ•°,
  "estimated_total_time": "é¢„è®¡æ€»å­¦ä¹ æ—¶é—´",
  "chapters": [
    {
      "chapter_number": ç« èŠ‚ç¼–å·,
      "title": "ç« èŠ‚æ ‡é¢˜",
      "subtitle": "å‰¯æ ‡é¢˜",
      "difficulty": "beginner/intermediate/advanced",
      "estimated_reading_time": "é¢„è®¡é˜…è¯»æ—¶é—´ï¼ˆåˆ†é’Ÿï¼‰",
      "learning_objectives": ["å­¦ä¹ ç›®æ ‡"],
      "key_concepts": ["æ ¸å¿ƒæ¦‚å¿µ"],
      "practical_exercises": ["å®è·µç»ƒä¹ "],
      "prerequisites": ["æœ¬ç« å‰ç½®çŸ¥è¯†"],
      "related_chapters": [ç›¸å…³ç« èŠ‚ç¼–å·],
      "content_outline": [
        "ä¸€çº§æ ‡é¢˜1",
        "  äºŒçº§æ ‡é¢˜1.1",
        "  äºŒçº§æ ‡é¢˜1.2",
        "ä¸€çº§æ ‡é¢˜2"
      ]
    }
  ],
  "learning_path": {
    "beginner_track": [ç« èŠ‚ç¼–å·åˆ—è¡¨],
    "intermediate_track": [ç« èŠ‚ç¼–å·åˆ—è¡¨],
    "advanced_track": [ç« èŠ‚ç¼–å·åˆ—è¡¨]
  },
  "suggested_projects": ["é¡¹ç›®å»ºè®®"],
  "references": ["å‚è€ƒèµ„æº"]
}

ç¡®ä¿è¾“å‡ºæœ‰æ•ˆçš„JSONï¼Œä¸åŒ…å«å…¶ä»–æ–‡å­—ã€‚"""
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                temperature=self.config['article_generation']['search_temperature'],
                max_tokens=self.config['article_generation']['max_tokens'],
            )
            
            content = response.choices[0].message.content
            
            # æ¸…ç†å’Œè§£æJSON
            content = content.strip()
            if content.startswith("```json"):
                content = content[7:]
            elif content.startswith("```"):
                content = content[3:]
            if content.endswith("```"):
                content = content[:-3]
            content = content.strip()
            
            curriculum = json.loads(content)
            
            # æ·»åŠ å…ƒæ•°æ®
            curriculum["generated_at"] = datetime.now().isoformat()
            curriculum["status"] = "generated"
            curriculum["topic_id"] = topic_data.get("main_topic")
            
            if verbose:
                print(f"âœ“ å¤§çº²ç”Ÿæˆå®Œæˆï¼")
                print(f"  æ•™ç¨‹åç§°: {curriculum.get('curriculum_name', 'N/A')}")
                print(f"  ç« èŠ‚æ•°é‡: {curriculum.get('total_chapters', 0)}")
                print(f"  é¢„è®¡æ—¶é—´: {curriculum.get('estimated_total_time', 'N/A')}\n")
                
                # æ˜¾ç¤ºç« èŠ‚åˆ—è¡¨
                print("ğŸ“š ç« èŠ‚åˆ—è¡¨:")
                for chapter in curriculum.get('chapters', []):
                    ch_num = chapter.get('chapter_number', '?')
                    title = chapter.get('title', 'æœªå‘½å')
                    difficulty = chapter.get('difficulty', 'N/A')
                    print(f"  ç¬¬{ch_num}ç« : {title} [{difficulty}]")
                print()
            
            # ä¿å­˜åˆ°æ•°æ®åº“
            self.curriculum_db["curriculums"].append(curriculum)
            self._save_json(self.curriculum_db_path, self.curriculum_db)
            print(f"âœ“ å¤§çº²å·²ä¿å­˜: {self.curriculum_db_path}\n")
            
            return curriculum
            
        except json.JSONDecodeError as e:
            print(f"âœ— JSONè§£æé”™è¯¯: {e}")
            print(f"åŸå§‹å†…å®¹:\n{content[:500]}...")
            raise
        except Exception as e:
            print(f"âœ— ç”Ÿæˆå¤±è´¥: {e}")
            raise
    
    def _find_topic(self, topic_name: str) -> Optional[Dict]:
        """åœ¨ä¸»é¢˜åº“ä¸­æŸ¥æ‰¾ä¸»é¢˜ï¼ˆæ”¯æŒæ¨¡ç³ŠåŒ¹é…ï¼‰"""
        import re
        
        def normalize_name(name: str) -> str:
            """è§„èŒƒåŒ–ä¸»é¢˜åç§°ï¼šç§»é™¤æ‰€æœ‰åˆ†éš”ç¬¦ã€ç»Ÿä¸€ä¸ºå°å†™"""
            name = name.lower()
            # ç§»é™¤æ‰€æœ‰æ‹¬å·ã€è¿å­—ç¬¦ã€ä¸‹åˆ’çº¿ã€ç©ºæ ¼
            name = re.sub(r'[ï¼ˆï¼‰()_\-\s]+', '', name)
            return name
        
        normalized_search = normalize_name(topic_name)
        
        # é¦–å…ˆå°è¯•ç²¾ç¡®åŒ¹é…
        for topic in self.topics_db.get("topics", []):
            topic_main = topic.get("main_topic", "")
            if normalize_name(topic_main) == normalized_search:
                return topic
        
        # å¦‚æœç²¾ç¡®åŒ¹é…å¤±è´¥ï¼Œå°è¯•éƒ¨åˆ†åŒ¹é…
        for topic in self.topics_db.get("topics", []):
            topic_main = normalize_name(topic.get("main_topic", ""))
            # æ£€æŸ¥æ˜¯å¦åŒ…å«æœç´¢è¯çš„ä¸»è¦éƒ¨åˆ†
            if normalized_search in topic_main or topic_main in normalized_search:
                print(f"  æç¤º: ä½¿ç”¨æ¨¡ç³ŠåŒ¹é…æ‰¾åˆ°ä¸»é¢˜ '{topic.get('main_topic')}'")
                return topic
        
        return None
    
    def _build_curriculum_prompt(self, topic_data: Dict) -> str:
        """æ„å»ºå¤§çº²ç”Ÿæˆæç¤ºè¯"""
        min_chapters = self.config['curriculum_generation']['min_chapters']
        max_chapters = self.config['curriculum_generation']['max_chapters']
        structure = self.config['curriculum_generation']['structure']
        
        subtopics_text = "\n".join([
            f"- {st['title']}: {st['description']} (éš¾åº¦: {st['difficulty']})"
            for st in topic_data.get('subtopics', [])
        ])
        
        return f"""è¯·ä¸ºä»¥ä¸‹æŠ€æœ¯ä¸»é¢˜è®¾è®¡ä¸€ä¸ªå®Œæ•´çš„æ•™ç¨‹ä½“ç³»ï¼š

ä¸»é¢˜ï¼š{topic_data.get('main_topic')}
ä¸»é¢˜æè¿°ï¼š{topic_data.get('description', '')}
éš¾åº¦çº§åˆ«ï¼š{topic_data.get('difficulty_level', 'intermediate')}

å·²å‘ç°çš„å­ä¸»é¢˜ï¼š
{subtopics_text}

å­¦ä¹ è·¯å¾„å»ºè®®ï¼š{topic_data.get('learning_path', '')}

è®¾è®¡è¦æ±‚ï¼š
1. ç« èŠ‚æ•°é‡åœ¨ {min_chapters}-{max_chapters} ç« ä¹‹é—´
2. éµå¾ªå¾ªåºæ¸è¿›çš„åŸåˆ™ï¼š{self.config['curriculum_generation']['progression_style']}
3. åŒ…å«ä»¥ä¸‹ç»“æ„å±‚æ¬¡ï¼š
{chr(10).join(f'   - {k}: {v}' for k, v in structure.items())}

4. æ¯ä¸ªç« èŠ‚åº”è¯¥ï¼š
   - æœ‰æ˜ç¡®çš„å­¦ä¹ ç›®æ ‡
   - åŒ…å«æ ¸å¿ƒæ¦‚å¿µè®²è§£
   - æä¾›å®è·µç»ƒä¹ ï¼ˆå¦‚é€‚ç”¨ï¼‰
   - æ ‡æ³¨éš¾åº¦çº§åˆ«å’Œå‰ç½®è¦æ±‚

5. æ•´ä½“è®¾è®¡è¦ï¼š
   - é€»è¾‘è¿è´¯ï¼Œå‰åå‘¼åº”
   - ç†è®ºä¸å®è·µç»“åˆ
   - é€‚åˆè‡ªå­¦å’Œæ•™å­¦

è¯·ç”Ÿæˆå®Œæ•´çš„æ•™ç¨‹å¤§çº²JSONã€‚"""
    
    def get_all_curriculums(self) -> List[Dict]:
        """è·å–æ‰€æœ‰æ•™ç¨‹å¤§çº²"""
        return self.curriculum_db.get("curriculums", [])
    
    def get_curriculum_by_topic(self, topic_name: str) -> Optional[Dict]:
        """æ ¹æ®ä¸»é¢˜åç§°è·å–æ•™ç¨‹å¤§çº²ï¼ˆæ”¯æŒæ¨¡ç³ŠåŒ¹é…ï¼‰"""
        import re
        
        def normalize_name(name: str) -> str:
            """è§„èŒƒåŒ–ä¸»é¢˜åç§°ï¼šç§»é™¤æ‰€æœ‰åˆ†éš”ç¬¦ã€ç»Ÿä¸€ä¸ºå°å†™"""
            name = name.lower()
            name = re.sub(r'[ï¼ˆï¼‰()_\-\s]+', '', name)
            return name
        
        normalized_search = normalize_name(topic_name)
        
        for curr in self.curriculum_db.get("curriculums", []):
            curr_topic = normalize_name(curr.get("main_topic", ""))
            if curr_topic == normalized_search or normalized_search in curr_topic or curr_topic in normalized_search:
                return curr
        return None
    
    def export_curriculum_markdown(self, curriculum: Dict, output_path: Optional[str] = None) -> str:
        """å¯¼å‡ºæ•™ç¨‹å¤§çº²ä¸ºMarkdownæ ¼å¼"""
        lines = []
        
        # æ ‡é¢˜
        lines.append(f"# {curriculum.get('curriculum_name', 'æ•™ç¨‹å¤§çº²')}")
        lines.append("")
        lines.append(f"**ä¸»é¢˜**: {curriculum.get('main_topic', 'N/A')}")
        lines.append(f"**ç›®æ ‡è¯»è€…**: {curriculum.get('target_audience', 'N/A')}")
        lines.append(f"**æ€»ç« èŠ‚æ•°**: {curriculum.get('total_chapters', 0)}")
        lines.append(f"**é¢„è®¡å­¦ä¹ æ—¶é—´**: {curriculum.get('estimated_total_time', 'N/A')}")
        lines.append("")
        
        # ç®€ä»‹
        lines.append("## è¯¾ç¨‹ç®€ä»‹")
        lines.append("")
        lines.append(curriculum.get('description', ''))
        lines.append("")
        
        # å‰ç½®è¦æ±‚
        if curriculum.get('prerequisites'):
            lines.append("## å‰ç½®è¦æ±‚")
            lines.append("")
            for prereq in curriculum['prerequisites']:
                lines.append(f"- {prereq}")
            lines.append("")
        
        # ç« èŠ‚åˆ—è¡¨
        lines.append("## ç« èŠ‚ç›®å½•")
        lines.append("")
        
        for chapter in curriculum.get('chapters', []):
            ch_num = chapter.get('chapter_number', '?')
            title = chapter.get('title', 'æœªå‘½å')
            subtitle = chapter.get('subtitle', '')
            difficulty = chapter.get('difficulty', '')
            time = chapter.get('estimated_reading_time', '')
            
            lines.append(f"### ç¬¬{ch_num}ç« : {title}")
            if subtitle:
                lines.append(f"*{subtitle}*")
            lines.append("")
            lines.append(f"**éš¾åº¦**: {difficulty} | **é¢„è®¡é˜…è¯»**: {time}åˆ†é’Ÿ")
            lines.append("")
            
            # å­¦ä¹ ç›®æ ‡
            if chapter.get('learning_objectives'):
                lines.append("**å­¦ä¹ ç›®æ ‡**:")
                for obj in chapter['learning_objectives']:
                    lines.append(f"- {obj}")
                lines.append("")
            
            # æ ¸å¿ƒæ¦‚å¿µ
            if chapter.get('key_concepts'):
                lines.append("**æ ¸å¿ƒæ¦‚å¿µ**: " + ", ".join(chapter['key_concepts']))
                lines.append("")
            
            # å†…å®¹å¤§çº²
            if chapter.get('content_outline'):
                lines.append("**å†…å®¹å¤§çº²**:")
                for item in chapter['content_outline']:
                    lines.append(f"{item}")
                lines.append("")
            
            lines.append("---")
            lines.append("")
        
        # å­¦ä¹ è·¯å¾„
        if curriculum.get('learning_path'):
            lines.append("## å­¦ä¹ è·¯å¾„")
            lines.append("")
            for track_name, chapters in curriculum['learning_path'].items():
                lines.append(f"**{track_name}**: ç« èŠ‚ {', '.join(map(str, chapters))}")
            lines.append("")
        
        # é¡¹ç›®å»ºè®®
        if curriculum.get('suggested_projects'):
            lines.append("## å®è·µé¡¹ç›®")
            lines.append("")
            for project in curriculum['suggested_projects']:
                lines.append(f"- {project}")
            lines.append("")
        
        # å‚è€ƒèµ„æº
        if curriculum.get('references'):
            lines.append("## å‚è€ƒèµ„æº")
            lines.append("")
            for ref in curriculum['references']:
                lines.append(f"- {ref}")
            lines.append("")
        
        markdown_content = "\n".join(lines)
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        if output_path:
            output_path = Path(output_path)
            output_path.parent.mkdir(parents=True, exist_ok=True)
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(markdown_content)
            print(f"âœ“ Markdownå¤§çº²å·²å¯¼å‡º: {output_path}")
        
        return markdown_content


def main():
    """æµ‹è¯•æ•™ç¨‹å¤§çº²ç”Ÿæˆå™¨"""
    import argparse
    
    parser = argparse.ArgumentParser(description='æ•™ç¨‹å¤§çº²ç”Ÿæˆå™¨')
    parser.add_argument('-t', '--topic', type=str, help='ä¸»é¢˜åç§°')
    parser.add_argument('-l', '--list', action='store_true', help='åˆ—å‡ºæ‰€æœ‰æ•™ç¨‹å¤§çº²')
    parser.add_argument('-e', '--export', type=str, help='å¯¼å‡ºæŒ‡å®šä¸»é¢˜çš„å¤§çº²ä¸ºMarkdown')
    parser.add_argument('-c', '--config', type=str, help='é…ç½®æ–‡ä»¶è·¯å¾„')
    
    args = parser.parse_args()
    
    try:
        generator = CurriculumGenerator(config_path=args.config)
        
        if args.list:
            curriculums = generator.get_all_curriculums()
            if not curriculums:
                print("è¿˜æ²¡æœ‰ç”Ÿæˆä»»ä½•æ•™ç¨‹å¤§çº²")
            else:
                print(f"\nå·²ç”Ÿæˆçš„æ•™ç¨‹å¤§çº² (å…± {len(curriculums)} ä¸ª):")
                print("=" * 70)
                for i, curr in enumerate(curriculums, 1):
                    print(f"{i}. {curr.get('curriculum_name', 'N/A')}")
                    print(f"   ä¸»é¢˜: {curr.get('main_topic', 'N/A')}")
                    print(f"   ç« èŠ‚æ•°: {curr.get('total_chapters', 0)}")
                    print(f"   ç”Ÿæˆæ—¶é—´: {curr.get('generated_at', 'N/A')}")
                    print()
        
        elif args.export:
            curriculum = generator.get_curriculum_by_topic(args.export)
            if not curriculum:
                print(f"æœªæ‰¾åˆ°ä¸»é¢˜ '{args.export}' çš„æ•™ç¨‹å¤§çº²")
                return
            
            safe_name = "".join(c if c.isalnum() or c in (' ', '-', '_') else '_' for c in args.export)
            output_path = Path(f"../posts/curriculum_{safe_name}.md")
            generator.export_curriculum_markdown(curriculum, output_path)
        
        elif args.topic:
            generator.generate_curriculum(args.topic)
        
        else:
            # äº¤äº’æ¨¡å¼
            print("\næ•™ç¨‹å¤§çº²ç”Ÿæˆå™¨")
            print("=" * 70)
            topic = input("è¯·è¾“å…¥ä¸»é¢˜åç§°: ").strip()
            if topic:
                curriculum = generator.generate_curriculum(topic)
                
                # è¯¢é—®æ˜¯å¦å¯¼å‡º
                export = input("\næ˜¯å¦å¯¼å‡ºä¸ºMarkdownï¼Ÿ(y/n): ").strip().lower()
                if export in ['y', 'yes']:
                    safe_name = "".join(c if c.isalnum() or c in (' ', '-', '_') else '_' for c in topic)
                    output_path = Path(f"../posts/curriculum_{safe_name}.md")
                    generator.export_curriculum_markdown(curriculum, output_path)
    
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
