#!/usr/bin/env python3
"""
reference_searcher.py

ä¸ºçƒ­ç‚¹è¯é¢˜æœç´¢ç›¸å…³è¾…åŠ©ææ–™
ä½¿ç”¨æ™ºè°±AIçš„Web SearchåŠŸèƒ½æ·±åº¦æœç´¢æŠ€æœ¯èƒŒæ™¯ã€åº”ç”¨æ¡ˆä¾‹ç­‰
"""

import os
import json
import time
from typing import List, Dict, Optional
from datetime import datetime
from zhipuai import ZhipuAI


class ReferenceSearcher:
    """å‚è€ƒèµ„æ–™æœç´¢å™¨ - ä¸ºå†…å®¹ç”Ÿæˆæä¾›ä¸°å¯Œçš„èƒŒæ™¯ææ–™"""
    
    def __init__(self, api_key: Optional[str] = None):
        """
        åˆå§‹åŒ–æ™ºè°±AIå®¢æˆ·ç«¯
        
        Args:
            api_key: APIå¯†é’¥ï¼Œå¦‚æœä¸ºNoneåˆ™ä»ç¯å¢ƒå˜é‡ZHIPUAI_API_KEYè¯»å–
        """
        self.api_key = api_key or os.environ.get("ZHIPUAI_API_KEY")
        if not self.api_key:
            raise ValueError("è¯·æä¾›æ™ºè°±AI API Keyï¼Œæˆ–è®¾ç½®ç¯å¢ƒå˜é‡ ZHIPUAI_API_KEY")
        
        self.client = ZhipuAI(api_key=self.api_key)
    
    def search_topic_references(
        self, 
        topic: str,
        original_summary: str = "",
        search_depth: str = "deep"
    ) -> Dict[str, any]:
        """
        ä¸ºç‰¹å®šè¯é¢˜æœç´¢å‚è€ƒèµ„æ–™
        
        Args:
            topic: è¯é¢˜æ ‡é¢˜
            original_summary: åŸå§‹æ‘˜è¦ï¼ˆå¯é€‰ï¼‰
            search_depth: æœç´¢æ·±åº¦ï¼Œ"quick"(å¿«é€Ÿ) æˆ– "deep"(æ·±åº¦)
            
        Returns:
            åŒ…å«å¤šç»´åº¦å‚è€ƒèµ„æ–™çš„å­—å…¸ï¼š
            {
                'topic': è¯é¢˜,
                'technical_background': æŠ€æœ¯èƒŒæ™¯,
                'key_innovations': å…³é”®åˆ›æ–°ç‚¹,
                'application_scenarios': åº”ç”¨åœºæ™¯,
                'industry_impact': è¡Œä¸šå½±å“,
                'related_technologies': ç›¸å…³æŠ€æœ¯,
                'search_results': åŸå§‹æœç´¢ç»“æœ
            }
        """
        print(f"\n{'='*70}")
        print(f"ğŸ” æ­£åœ¨ä¸ºè¯é¢˜æœç´¢å‚è€ƒèµ„æ–™: {topic}")
        print(f"{'='*70}\n")
        
        references = {
            'topic': topic,
            'original_summary': original_summary,
            'searched_at': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            'technical_background': "",
            'key_innovations': [],
            'application_scenarios': [],
            'industry_impact': "",
            'related_technologies': [],
            'search_results': ""
        }
        
        try:
            # ç¬¬ä¸€æ­¥ï¼šæœç´¢æŠ€æœ¯èƒŒæ™¯å’Œæœ€æ–°è¿›å±•
            print("ğŸ“š [1/3] æœç´¢æŠ€æœ¯èƒŒæ™¯å’Œæœ€æ–°è¿›å±•...")
            background = self._search_technical_background(topic, original_summary)
            references['technical_background'] = background['content']
            references['search_results'] = background['raw_results']
            print(f"  âœ“ æ‰¾åˆ° {len(background['content'])} å­—æŠ€æœ¯èƒŒæ™¯èµ„æ–™")
            
            # ç¬¬äºŒæ­¥ï¼šæœç´¢åº”ç”¨åœºæ™¯å’Œæ¡ˆä¾‹
            if search_depth == "deep":
                time.sleep(1)  # é¿å…APIè¯·æ±‚è¿‡å¿«
                print("\nğŸ’¡ [2/3] æœç´¢åº”ç”¨åœºæ™¯å’Œå®é™…æ¡ˆä¾‹...")
                applications = self._search_applications(topic)
                references['application_scenarios'] = applications['scenarios']
                references['key_innovations'] = applications['innovations']
                print(f"  âœ“ æ‰¾åˆ° {len(applications['scenarios'])} ä¸ªåº”ç”¨åœºæ™¯")
                print(f"  âœ“ æå– {len(applications['innovations'])} ä¸ªåˆ›æ–°ç‚¹")
                
                # ç¬¬ä¸‰æ­¥ï¼šæœç´¢è¡Œä¸šå½±å“å’Œç›¸å…³æŠ€æœ¯
                time.sleep(1)
                print("\nğŸŒ [3/3] æœç´¢è¡Œä¸šå½±å“å’Œç›¸å…³æŠ€æœ¯...")
                context = self._search_industry_context(topic)
                references['industry_impact'] = context['impact']
                references['related_technologies'] = context['related_tech']
                print(f"  âœ“ æ‰¾åˆ° {len(context['impact'])} å­—è¡Œä¸šå½±å“åˆ†æ")
                print(f"  âœ“ æå– {len(context['related_tech'])} ä¸ªç›¸å…³æŠ€æœ¯")
            else:
                print("  âš¡ å¿«é€Ÿæ¨¡å¼ï¼šè·³è¿‡æ·±åº¦æœç´¢")
            
            print(f"\n{'='*70}")
            print(f"âœ… å‚è€ƒèµ„æ–™æœç´¢å®Œæˆ")
            print(f"{'='*70}\n")
            
            return references
            
        except Exception as e:
            print(f"\nâŒ æœç´¢å¤±è´¥: {e}")
            return references
    
    def _search_technical_background(
        self, 
        topic: str, 
        summary: str
    ) -> Dict[str, str]:
        """
        æœç´¢æŠ€æœ¯èƒŒæ™¯
        
        Returns:
            {'content': æ•´ç†åçš„å†…å®¹, 'raw_results': åŸå§‹æœç´¢ç»“æœ}
        """
        # æ„å»ºæœç´¢æŸ¥è¯¢
        search_query = f"{topic} æŠ€æœ¯åŸç† å‘å±•å†ç¨‹ æœ€æ–°è¿›å±•"
        if summary:
            search_query += f" {summary}"
        
        # é…ç½®æœç´¢å·¥å…·
        tools = [{
            "type": "web_search",
            "web_search": {
                "enable": True,
                "search_result": True
            }
        }]
        
        messages = [{
            "role": "user",
            "content": f"""è¯·æœç´¢å…³äº"{topic}"çš„æŠ€æœ¯èƒŒæ™¯ä¿¡æ¯ï¼ŒåŒ…æ‹¬ï¼š
1. æŠ€æœ¯åŸç†å’Œæ ¸å¿ƒæ¦‚å¿µ
2. å‘å±•å†ç¨‹å’Œæ¼”è¿›è¿‡ç¨‹
3. æœ€æ–°çš„æŠ€æœ¯çªç ´å’Œè¿›å±•
4. æŠ€æœ¯ä¼˜åŠ¿å’Œç‰¹ç‚¹

è¯·æä¾›è¯¦ç»†ã€å‡†ç¡®çš„æŠ€æœ¯ä¿¡æ¯ã€‚"""
        }]
        
        try:
            response = self.client.chat.completions.create(
                model="glm-4-flash",
                messages=messages,
                tools=tools,
                temperature=0.3
            )
            
            content = response.choices[0].message.content
            
            # æå–ç»“æ„åŒ–å†…å®¹
            structured = self._extract_structured_content(content, "technical_background")
            
            return {
                'content': structured,
                'raw_results': content
            }
            
        except Exception as e:
            print(f"  âš ï¸ æŠ€æœ¯èƒŒæ™¯æœç´¢å¤±è´¥: {e}")
            return {'content': '', 'raw_results': ''}
    
    def _search_applications(self, topic: str) -> Dict[str, List]:
        """
        æœç´¢åº”ç”¨åœºæ™¯å’Œåˆ›æ–°ç‚¹
        
        Returns:
            {'scenarios': åº”ç”¨åœºæ™¯åˆ—è¡¨, 'innovations': åˆ›æ–°ç‚¹åˆ—è¡¨}
        """
        tools = [{
            "type": "web_search",
            "web_search": {
                "enable": True,
                "search_result": True
            }
        }]
        
        messages = [{
            "role": "user",
            "content": f"""è¯·æœç´¢å…³äº"{topic}"çš„å®é™…åº”ç”¨ä¿¡æ¯ï¼š
1. å…¸å‹åº”ç”¨åœºæ™¯ï¼ˆè‡³å°‘3ä¸ªï¼‰
2. æˆåŠŸæ¡ˆä¾‹æˆ–è½åœ°é¡¹ç›®
3. å…³é”®åˆ›æ–°ç‚¹å’Œçªç ´
4. æŠ€æœ¯ä»·å€¼å’Œä¸šåŠ¡ä»·å€¼

è¯·æä¾›å…·ä½“çš„åº”ç”¨æ¡ˆä¾‹å’Œåˆ›æ–°ç‚¹ã€‚"""
        }]
        
        try:
            response = self.client.chat.completions.create(
                model="glm-4-flash",
                messages=messages,
                tools=tools,
                temperature=0.3
            )
            
            content = response.choices[0].message.content
            
            # æå–åº”ç”¨åœºæ™¯å’Œåˆ›æ–°ç‚¹
            scenarios, innovations = self._extract_applications_and_innovations(content)
            
            return {
                'scenarios': scenarios,
                'innovations': innovations
            }
            
        except Exception as e:
            print(f"  âš ï¸ åº”ç”¨åœºæ™¯æœç´¢å¤±è´¥: {e}")
            return {'scenarios': [], 'innovations': []}
    
    def _search_industry_context(self, topic: str) -> Dict[str, any]:
        """
        æœç´¢è¡Œä¸šå½±å“å’Œç›¸å…³æŠ€æœ¯
        
        Returns:
            {'impact': è¡Œä¸šå½±å“, 'related_tech': ç›¸å…³æŠ€æœ¯åˆ—è¡¨}
        """
        tools = [{
            "type": "web_search",
            "web_search": {
                "enable": True,
                "search_result": True
            }
        }]
        
        messages = [{
            "role": "user",
            "content": f"""è¯·æœç´¢å…³äº"{topic}"çš„è¡Œä¸šå½±å“å’ŒæŠ€æœ¯ç”Ÿæ€ï¼š
1. å¯¹ç›¸å…³è¡Œä¸šçš„å½±å“å’Œæ”¹å˜
2. æœªæ¥å‘å±•è¶‹åŠ¿
3. ç›¸å…³çš„æŠ€æœ¯æ ˆå’ŒæŠ€æœ¯ä½“ç³»
4. ç«äº‰æ ¼å±€å’Œå¸‚åœºåŠ¨æ€

è¯·æä¾›å®è§‚çš„è¡Œä¸šè§†è§’åˆ†æã€‚"""
        }]
        
        try:
            response = self.client.chat.completions.create(
                model="glm-4-flash",
                messages=messages,
                tools=tools,
                temperature=0.3
            )
            
            content = response.choices[0].message.content
            
            # æå–è¡Œä¸šå½±å“å’Œç›¸å…³æŠ€æœ¯
            impact, related_tech = self._extract_industry_info(content)
            
            return {
                'impact': impact,
                'related_tech': related_tech
            }
            
        except Exception as e:
            print(f"  âš ï¸ è¡Œä¸šåˆ†ææœç´¢å¤±è´¥: {e}")
            return {'impact': '', 'related_tech': []}
    
    def _extract_structured_content(self, content: str, content_type: str) -> str:
        """
        ä½¿ç”¨AIæå–å’Œæ•´ç†ç»“æ„åŒ–å†…å®¹
        """
        prompt = f"""è¯·ä»ä»¥ä¸‹æœç´¢ç»“æœä¸­æå–å’Œæ•´ç†æŠ€æœ¯èƒŒæ™¯ä¿¡æ¯ï¼Œè¦æ±‚ï¼š
1. å†…å®¹å‡†ç¡®ã€å®¢è§‚
2. é‡ç‚¹çªå‡ºæŠ€æœ¯åŸç†å’Œæ ¸å¿ƒæ¦‚å¿µ
3. åŒ…å«æœ€æ–°è¿›å±•
4. 300-500å­—
5. ä½¿ç”¨æµç•…çš„å™è¿°æ–¹å¼ï¼Œä¸è¦åˆ—è¡¨å½¢å¼

æœç´¢ç»“æœï¼š
{content}

è¯·ç›´æ¥è¾“å‡ºæ•´ç†åçš„å†…å®¹ï¼š"""
        
        try:
            response = self.client.chat.completions.create(
                model="glm-4-flash",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.5
            )
            
            return response.choices[0].message.content.strip()
        except:
            return content[:500]  # é™çº§ï¼šç›´æ¥æˆªå–
    
    def _extract_applications_and_innovations(self, content: str) -> tuple:
        """
        æå–åº”ç”¨åœºæ™¯å’Œåˆ›æ–°ç‚¹
        """
        prompt = f"""è¯·ä»ä»¥ä¸‹å†…å®¹ä¸­æå–ï¼š
1. åº”ç”¨åœºæ™¯ï¼ˆ3-5ä¸ªï¼Œæ¯ä¸ª30-50å­—ï¼‰
2. å…³é”®åˆ›æ–°ç‚¹ï¼ˆ3-5ä¸ªï¼Œæ¯ä¸ª20-30å­—ï¼‰

è¾“å‡ºJSONæ ¼å¼ï¼š
{{
    "scenarios": ["åœºæ™¯1", "åœºæ™¯2", ...],
    "innovations": ["åˆ›æ–°ç‚¹1", "åˆ›æ–°ç‚¹2", ...]
}}

å†…å®¹ï¼š
{content}

è¯·ç›´æ¥è¾“å‡ºJSONï¼š"""
        
        try:
            response = self.client.chat.completions.create(
                model="glm-4-flash",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.3
            )
            
            result_text = response.choices[0].message.content.strip()
            result_text = result_text.replace('```json', '').replace('```', '').strip()
            
            data = json.loads(result_text)
            return data.get('scenarios', []), data.get('innovations', [])
        except:
            return [], []
    
    def _extract_industry_info(self, content: str) -> tuple:
        """
        æå–è¡Œä¸šå½±å“å’Œç›¸å…³æŠ€æœ¯
        """
        prompt = f"""è¯·ä»ä»¥ä¸‹å†…å®¹ä¸­æå–ï¼š
1. è¡Œä¸šå½±å“ï¼ˆ200-300å­—çš„åˆ†æï¼‰
2. ç›¸å…³æŠ€æœ¯ï¼ˆ3-5ä¸ªæŠ€æœ¯åç§°ï¼‰

è¾“å‡ºJSONæ ¼å¼ï¼š
{{
    "impact": "è¡Œä¸šå½±å“åˆ†ææ–‡æœ¬",
    "related_technologies": ["æŠ€æœ¯1", "æŠ€æœ¯2", ...]
}}

å†…å®¹ï¼š
{content}

è¯·ç›´æ¥è¾“å‡ºJSONï¼š"""
        
        try:
            response = self.client.chat.completions.create(
                model="glm-4-flash",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.3
            )
            
            result_text = response.choices[0].message.content.strip()
            result_text = result_text.replace('```json', '').replace('```', '').strip()
            
            data = json.loads(result_text)
            return data.get('impact', ''), data.get('related_technologies', [])
        except:
            return '', []
    
    def batch_search(
        self, 
        topics: List[Dict[str, str]], 
        delay: float = 2.0
    ) -> List[Dict]:
        """
        æ‰¹é‡æœç´¢å¤šä¸ªè¯é¢˜çš„å‚è€ƒèµ„æ–™
        
        Args:
            topics: è¯é¢˜åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å« {'title': æ ‡é¢˜, 'summary': æ‘˜è¦}
            delay: è¯·æ±‚é—´éš”ï¼ˆç§’ï¼‰ï¼Œé¿å…APIé™æµ
            
        Returns:
            å‚è€ƒèµ„æ–™åˆ—è¡¨
        """
        print(f"\n{'='*70}")
        print(f"ğŸ” æ‰¹é‡æœç´¢ {len(topics)} ä¸ªè¯é¢˜çš„å‚è€ƒèµ„æ–™")
        print(f"{'='*70}\n")
        
        all_references = []
        
        for idx, topic_info in enumerate(topics, 1):
            print(f"\n[{idx}/{len(topics)}] å¤„ç†è¯é¢˜: {topic_info.get('title', '')}")
            
            try:
                references = self.search_topic_references(
                    topic=topic_info.get('title', ''),
                    original_summary=topic_info.get('summary', ''),
                    search_depth="quick" if len(topics) > 5 else "deep"  # å¤šè¯é¢˜æ—¶ä½¿ç”¨å¿«é€Ÿæ¨¡å¼
                )
                all_references.append(references)
                
                # å»¶è¿Ÿï¼Œé¿å…è¯·æ±‚è¿‡å¿«
                if idx < len(topics):
                    time.sleep(delay)
                    
            except Exception as e:
                print(f"  âŒ å¤„ç†å¤±è´¥: {e}")
                continue
        
        print(f"\n{'='*70}")
        print(f"âœ… æ‰¹é‡æœç´¢å®Œæˆï¼ŒæˆåŠŸå¤„ç† {len(all_references)}/{len(topics)} ä¸ªè¯é¢˜")
        print(f"{'='*70}\n")
        
        return all_references


def main():
    """æµ‹è¯•å‚è€ƒèµ„æ–™æœç´¢åŠŸèƒ½"""
    searcher = ReferenceSearcher()
    
    # æµ‹è¯•å•ä¸ªè¯é¢˜æœç´¢
    test_topic = "Kimi K2 Thinking AIæ™ºèƒ½ä½“"
    test_summary = "æ¨¡å‹å³Agentï¼Œè¶…GPT-5çš„æ¨ç†èƒ½åŠ›"
    
    references = searcher.search_topic_references(
        topic=test_topic,
        original_summary=test_summary,
        search_depth="deep"
    )
    
    # æ‰“å°ç»“æœ
    print("\n" + "="*70)
    print("ğŸ“‹ æœç´¢ç»“æœæ±‡æ€»")
    print("="*70 + "\n")
    
    print(f"è¯é¢˜: {references['topic']}")
    print(f"\næŠ€æœ¯èƒŒæ™¯:\n{references['technical_background'][:300]}...")
    print(f"\nå…³é”®åˆ›æ–°ç‚¹: {', '.join(references['key_innovations'][:3])}")
    print(f"\nåº”ç”¨åœºæ™¯: {', '.join(references['application_scenarios'][:3])}")
    
    # ä¿å­˜ä¸ºJSON
    output_file = "data/reference_example.json"
    os.makedirs("data", exist_ok=True)
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(references, f, ensure_ascii=False, indent=2)
    print(f"\nâœ… å‚è€ƒèµ„æ–™å·²ä¿å­˜åˆ°: {output_file}")


if __name__ == "__main__":
    main()
