# å†…å®¹è‡ªåŠ¨ç”Ÿæˆæ¨¡å—

## ğŸ“– æ¦‚è¿°

åŸºäºå·²æœ‰çš„å†…å®¹åˆ†å‘ç³»ç»Ÿï¼Œæœ¬æ¨¡å—å®ç°äº†**å†…å®¹è‡ªåŠ¨ç”Ÿæˆ**åŠŸèƒ½ï¼Œæ„å»ºå®Œæ•´çš„"å†…å®¹ç”Ÿæˆ -> å†…å®¹åˆ†å‘"é—­ç¯ã€‚

### æ ¸å¿ƒæµç¨‹

```
é‡å­ä½çƒ­ç‚¹æŠ“å– â†’ æ™ºè°±AIæœç´¢èµ„æ–™ â†’ AIç”Ÿæˆæ–‡ç«  â†’ ä¿å­˜åˆ°posts â†’ è‡ªåŠ¨åˆ†å‘åˆ°å„å¹³å°
```

## ğŸ¯ åŠŸèƒ½ç‰¹æ€§

### 1. é‡å­ä½çƒ­ç‚¹æŠ“å– (`qbitai_crawler.py`)
- è‡ªåŠ¨æŠ“å–é‡å­ä½ï¼ˆqbitai.comï¼‰é¦–é¡µTOPçƒ­ç‚¹æ–°é—»
- æå–æ ‡é¢˜ã€é“¾æ¥ã€æ‘˜è¦ã€ä½œè€…ã€æ—¶é—´ã€æ ‡ç­¾ã€å°é¢å›¾ç­‰ä¿¡æ¯
- æ”¯æŒè‡ªå®šä¹‰æŠ“å–æ•°é‡
- é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶

### 2. æ™ºèƒ½å‚è€ƒèµ„æ–™æœç´¢ (`reference_searcher.py`)
- åŸºäºæ™ºè°±AI Web Search APIæœç´¢ç›¸å…³æŠ€æœ¯èµ„æ–™
- å¤šç»´åº¦ä¿¡æ¯æ”¶é›†:
  - æŠ€æœ¯èƒŒæ™¯å’Œæ ¸å¿ƒæ¦‚å¿µ
  - å…³é”®åˆ›æ–°ç‚¹
  - åº”ç”¨åœºæ™¯å’Œæ¡ˆä¾‹
  - è¡Œä¸šå½±å“å’Œè¶‹åŠ¿
  - ç›¸å…³æŠ€æœ¯æ ˆ
- æ”¯æŒå¿«é€Ÿ/æ·±åº¦ä¸¤ç§æœç´¢æ¨¡å¼

### 3. é«˜ä»¿é£æ ¼å†…å®¹ç”Ÿæˆ (`enhanced_content_generator.py`)
- **æ¨¡ä»¿é‡å­ä½å†™ä½œé£æ ¼**ï¼šæ–°é—»åŒ–ã€æ•°æ®åŒ–ã€åœºæ™¯åŒ–
- **ä¿æŒå†…å®¹å·®å¼‚æ€§**ï¼šåŒä¸€è¯é¢˜ä¸åŒè§’åº¦å’Œè¡¨è¾¾
- è‡ªåŠ¨ç”Ÿæˆåˆ›æ–°æ ‡é¢˜
- æ™ºèƒ½æå–æ ‡ç­¾å’Œæè¿°
- è‡ªåŠ¨æ·»åŠ Front Matterï¼ˆæ”¯æŒé™æ€åšå®¢ï¼‰

### 4. è‡ªåŠ¨åŒ–æµæ°´çº¿ (`auto_content_pipeline.py`)
- ç«¯åˆ°ç«¯è‡ªåŠ¨åŒ–æ‰§è¡Œ
- æ‰¹é‡å¤„ç†å¤šä¸ªçƒ­ç‚¹
- APIè¯·æ±‚é™æµå’Œé”™è¯¯æ¢å¤
- ä¸­é—´ç»“æœä¿å­˜
- è¯¦ç»†è¿è¡ŒæŠ¥å‘Š

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒå‡†å¤‡

```bash
# 1. å®‰è£…ä¾èµ–
pip install zhipuai requests beautifulsoup4 pyyaml

# 2. è®¾ç½®APIå¯†é’¥
export ZHIPUAI_API_KEY="your-api-key-here"
```

### åŸºæœ¬ä½¿ç”¨

#### æ–¹æ³•ä¸€ï¼šä½¿ç”¨è‡ªåŠ¨åŒ–æµæ°´çº¿ï¼ˆæ¨èï¼‰

```bash
# ä½¿ç”¨é»˜è®¤é…ç½®ï¼ˆæŠ“å–10æ¡ï¼Œç”Ÿæˆ5ç¯‡ï¼‰
python generate/auto_content_pipeline.py

# è‡ªå®šä¹‰å‚æ•°
python generate/auto_content_pipeline.py \
  --news-limit 15 \        # æŠ“å–15æ¡æ–°é—»
  --article-limit 10 \     # ç”Ÿæˆ10ç¯‡æ–‡ç« 
  --search-depth deep \    # æ·±åº¦æœç´¢
  --delay 3.0 \            # 3ç§’è¯·æ±‚é—´éš”
  --output-dir posts       # è¾“å‡ºåˆ°postsç›®å½•
```

#### æ–¹æ³•äºŒï¼šåˆ†æ­¥æ‰§è¡Œ

```python
from generate.qbitai_crawler import QbitAICrawler
from generate.reference_searcher import ReferenceSearcher
from generate.enhanced_content_generator import EnhancedContentGenerator

# 1. æŠ“å–çƒ­ç‚¹
crawler = QbitAICrawler()
news_list = crawler.fetch_top_news(limit=10)

# 2. æœç´¢èµ„æ–™
searcher = ReferenceSearcher()
references = searcher.search_topic_references(
    topic=news_list[0]['title'],
    original_summary=news_list[0]['summary']
)

# 3. ç”Ÿæˆæ–‡ç« 
generator = EnhancedContentGenerator()
article = generator.generate_article_from_news(
    news_item=news_list[0],
    references=references,
    style="qbitai"
)

print(f"æ–‡ç« å·²ä¿å­˜: {article['file_path']}")
```

## ğŸ“ ç›®å½•ç»“æ„

```
generate/
â”œâ”€â”€ qbitai_crawler.py              # é‡å­ä½æ–°é—»çˆ¬è™«
â”œâ”€â”€ reference_searcher.py          # å‚è€ƒèµ„æ–™æœç´¢å™¨
â”œâ”€â”€ enhanced_content_generator.py  # å¢å¼ºç‰ˆå†…å®¹ç”Ÿæˆå™¨
â”œâ”€â”€ auto_content_pipeline.py       # è‡ªåŠ¨åŒ–æµæ°´çº¿
â”œâ”€â”€ zhipu_content_generator.py     # åŸºç¡€å†…å®¹ç”Ÿæˆå™¨ï¼ˆå·²æœ‰ï¼‰
â””â”€â”€ zhipu_news_search.py           # æ–°é—»æœç´¢åŠŸèƒ½ï¼ˆå·²æœ‰ï¼‰

config/
â””â”€â”€ content_generation.yaml        # å†…å®¹ç”Ÿæˆé…ç½®æ–‡ä»¶

data/
â””â”€â”€ generated/                     # ç”Ÿæˆçš„ä¸­é—´æ•°æ®
    â”œâ”€â”€ 01_crawled_news.json       # æŠ“å–çš„æ–°é—»
    â”œâ”€â”€ 02_search_references.json  # æœç´¢çš„å‚è€ƒèµ„æ–™
    â”œâ”€â”€ 03_generated_articles.json # ç”Ÿæˆçš„æ–‡ç« åˆ—è¡¨
    â””â”€â”€ 04_pipeline_report.txt     # è¿è¡ŒæŠ¥å‘Š

posts/                             # ç”Ÿæˆçš„æ–‡ç« ï¼ˆMarkdownï¼‰
```

## ğŸ”§ é…ç½®è¯´æ˜

ç¼–è¾‘ `config/content_generation.yaml` è¿›è¡Œé…ç½®ï¼š

```yaml
# APIé…ç½®
api:
  request_delay: 2.0    # APIè¯·æ±‚é—´éš”ï¼ˆç§’ï¼‰
  timeout: 30           # è¯·æ±‚è¶…æ—¶æ—¶é—´

# çˆ¬è™«é…ç½®
crawler:
  news_limit: 10        # æŠ“å–æ–°é—»æ•°é‡

# æœç´¢é…ç½®
search:
  depth: "quick"        # quick(å¿«é€Ÿ) æˆ– deep(æ·±åº¦)
  enabled: true         # æ˜¯å¦å¯ç”¨æœç´¢

# ç”Ÿæˆé…ç½®
generator:
  article_limit: 5      # ç”Ÿæˆæ–‡ç« æ•°é‡
  style: "qbitai"       # å†™ä½œé£æ ¼
  min_words: 1500       # æœ€å°å­—æ•°
  max_words: 2500       # æœ€å¤§å­—æ•°

# è¾“å‡ºé…ç½®
output:
  articles_dir: "posts" # æ–‡ç« è¾“å‡ºç›®å½•
  save_intermediate: true # ä¿å­˜ä¸­é—´ç»“æœ
```

## ğŸ“Š ç”Ÿæˆæ•ˆæœç¤ºä¾‹

### åŸå§‹æ–°é—»æ ‡é¢˜ï¼ˆé‡å­ä½ï¼‰
```
Kimi K2 Thinkingçªè¢­ï¼æ™ºèƒ½ä½“&æ¨ç†èƒ½åŠ›è¶…GPT-5ï¼Œç½‘å‹ï¼šå†æ¬¡ç¼©å°å¼€æºé—­æºå·®è·
```

### ç”Ÿæˆçš„æ–°æ ‡é¢˜
```
Kimi K2 Thinkingå¼ºåŠ¿æ¥è¢­ï¼šåŸç”Ÿæ™ºèƒ½ä½“èƒ½åŠ›è¶…è¶ŠGPT-5ï¼Œå›½äº§AIå†åˆ›æ–°é«˜ï¼
```

### æ–‡ç« ç‰¹ç‚¹
- âœ… ä¿æŒé‡å­ä½çš„æ–°é—»åŒ–é£æ ¼
- âœ… æŠ€æœ¯æ·±åº¦å’Œå‡†ç¡®æ€§
- âœ… æ•°æ®é©±åŠ¨çš„å™è¿°æ–¹å¼
- âœ… èå…¥ç½‘å‹è¯„è®ºå’Œè¡Œä¸šè§‚ç‚¹
- âœ… å®Œæ•´çš„Markdownæ ¼å¼å’ŒFront Matter

## ğŸ¨ å†™ä½œé£æ ¼ç‰¹å¾

### é‡å­ä½é£æ ¼æ¨¡ä»¿
1. **æ ‡é¢˜ç‰¹ç‚¹**: ç®€æ´æœ‰åŠ›ï¼Œçªå‡º"é¦–ä¸ª"ã€"çªè¢­"ã€"æš´æ¶¨"ç­‰å†²å‡»æ€§è¯æ±‡
2. **å¼€ç¯‡æ–¹å¼**: ç›´æ¥æŠ›å‡ºæ ¸å¿ƒä¿¡æ¯æˆ–æ•°æ®ï¼Œè¥é€ è¯é¢˜æ„Ÿ
3. **å™è¿°èŠ‚å¥**: æ–°é—»å¼æŠ¥é“ä¸æŠ€æœ¯è§£æç»“åˆï¼ŒèŠ‚å¥ç´§å‡‘
4. **å¼•ç”¨é£æ ¼**: ä½¿ç”¨"ç½‘å‹è¯„è®º"ã€"ä¸šå†…äººå£«è¡¨ç¤º"ç­‰
5. **æ•°æ®å±•ç¤º**: çªå‡ºå…³é”®æ•°æ®å’Œå¯¹æ¯”
6. **æ®µè½ç»“æ„**: çŸ­å°ç²¾æ‚ï¼Œæ˜“è¯»æ€§å¼º

## ğŸ”„ ä¸åˆ†å‘ç³»ç»Ÿé›†æˆ

ç”Ÿæˆçš„æ–‡ç« ä¼šè‡ªåŠ¨ä¿å­˜åˆ° `posts/` ç›®å½•ï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨ç°æœ‰çš„åˆ†å‘ç³»ç»Ÿï¼š

```bash
# 1. ç”Ÿæˆå†…å®¹
python generate/auto_content_pipeline.py --article-limit 5

# 2. åˆ†å‘åˆ°å„å¹³å°
python publish.py posts/ç”Ÿæˆçš„æ–‡ç« .md

# æˆ–æ‰¹é‡åˆ†å‘
python batch_publish.py
```

## ğŸ“ˆ æ€§èƒ½æŒ‡æ ‡

### å•ç¯‡æ–‡ç« ç”Ÿæˆæ—¶é—´
- æ–°é—»æŠ“å–: ~2ç§’
- èµ„æ–™æœç´¢ï¼ˆå¿«é€Ÿæ¨¡å¼ï¼‰: ~5-10ç§’
- èµ„æ–™æœç´¢ï¼ˆæ·±åº¦æ¨¡å¼ï¼‰: ~20-30ç§’
- å†…å®¹ç”Ÿæˆ: ~15-30ç§’
- **æ€»è®¡ï¼ˆå¿«é€Ÿæ¨¡å¼ï¼‰**: çº¦30-45ç§’/ç¯‡

### æ‰¹é‡ç”Ÿæˆæ•ˆç‡
- 10æ¡çƒ­ç‚¹ â†’ 5ç¯‡æ–‡ç« : çº¦3-5åˆ†é’Ÿ
- åŒ…å«å®Œæ•´çš„æŠ“å–ã€æœç´¢ã€ç”Ÿæˆæµç¨‹

## ğŸ› ï¸ é«˜çº§ç”¨æ³•

### è‡ªå®šä¹‰é£æ ¼æ¨¡æ¿

```python
generator = EnhancedContentGenerator()

# è‡ªå®šä¹‰é£æ ¼ï¼ˆç¼–è¾‘ç±»ä¸­çš„QBITAI_STYLEå¸¸é‡ï¼‰
# æˆ–åˆ›å»ºæ–°çš„é£æ ¼æ¨¡æ¿
```

### æ‰¹é‡æœç´¢å‚è€ƒèµ„æ–™

```python
searcher = ReferenceSearcher()

topics = [
    {'title': 'è¯é¢˜1', 'summary': 'æ‘˜è¦1'},
    {'title': 'è¯é¢˜2', 'summary': 'æ‘˜è¦2'}
]

references_list = searcher.batch_search(topics, delay=2.0)
```

### åªæŠ“å–ä¸ç”Ÿæˆ

```python
crawler = QbitAICrawler()
news_list = crawler.fetch_top_news(limit=20)
crawler.save_to_json(news_list, "hot_topics.json")
```

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **APIé™æµ**: å»ºè®®è®¾ç½®2-3ç§’çš„è¯·æ±‚é—´éš”ï¼Œé¿å…è§¦å‘é™æµ
2. **çˆ¬è™«ç¤¼ä»ª**: åˆç†æ§åˆ¶æŠ“å–é¢‘ç‡ï¼Œéµå®ˆç½‘ç«™robots.txt
3. **å†…å®¹å®¡æ ¸**: ç”Ÿæˆçš„å†…å®¹å»ºè®®äººå·¥å®¡æ ¸åå†å‘å¸ƒ
4. **ç‰ˆæƒé—®é¢˜**: ç¡®ä¿ç”Ÿæˆçš„å†…å®¹ä¸ä¾µçŠ¯åŸåˆ›ç‰ˆæƒ
5. **APIæˆæœ¬**: æ³¨æ„æ§åˆ¶ç”Ÿæˆæ•°é‡ï¼Œé¿å…è¶…å‡ºAPIé…é¢

## ğŸ› æ•…éšœæ’æŸ¥

### é—®é¢˜1: çˆ¬è™«æŠ“å–å¤±è´¥
```bash
# æ£€æŸ¥ç½‘ç»œè¿æ¥
curl https://www.qbitai.com

# æ£€æŸ¥User-Agentå’Œè¯·æ±‚å¤´
```

### é—®é¢˜2: APIè°ƒç”¨å¤±è´¥
```bash
# æ£€æŸ¥APIå¯†é’¥
echo $ZHIPUAI_API_KEY

# æ£€æŸ¥é…é¢å’Œé™æµ
```

### é—®é¢˜3: ç”Ÿæˆå†…å®¹è´¨é‡ä¸ä½³
- å°è¯•ä½¿ç”¨ `--search-depth deep` è·å–æ›´å¤šå‚è€ƒèµ„æ–™
- è°ƒæ•´ `temperature` å‚æ•°ï¼ˆåœ¨ä»£ç ä¸­ï¼‰
- å¢åŠ æœ€å°å­—æ•°è¦æ±‚

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [ä¸»é¡¹ç›®README](../README.md) - é¡¹ç›®æ•´ä½“è¯´æ˜
- [åˆ†å‘æ¨¡å—æ–‡æ¡£](../docs/USAGE.md) - å†…å®¹åˆ†å‘ä½¿ç”¨æŒ‡å—
- [æ™ºè°±AIæ–‡æ¡£](https://open.bigmodel.cn/dev/api) - APIæ¥å£æ–‡æ¡£

## ğŸ”® æœªæ¥è®¡åˆ’

- [ ] æ”¯æŒæ›´å¤šæ–°é—»æºï¼ˆæœºå™¨ä¹‹å¿ƒã€InfoQç­‰ï¼‰
- [ ] å›¾ç‰‡è‡ªåŠ¨ä¸‹è½½å’Œæ‰˜ç®¡
- [ ] å¤šé£æ ¼æ¨¡æ¿ï¼ˆæ­£å¼ã€è½»æ¾ã€æŠ€æœ¯æ·±åº¦ç­‰ï¼‰
- [ ] è‡ªåŠ¨åŒ–å®šæ—¶ä»»åŠ¡
- [ ] å†…å®¹è´¨é‡è¯„åˆ†ç³»ç»Ÿ
- [ ] ä¸åˆ†å‘ç³»ç»Ÿæ·±åº¦é›†æˆ

## ğŸ’¡ ä½¿ç”¨å»ºè®®

1. **é¦–æ¬¡ä½¿ç”¨**: å»ºè®®å…ˆç”¨ `--article-limit 1` æµ‹è¯•å•ç¯‡ç”Ÿæˆæ•ˆæœ
2. **æ—¥å¸¸ä½¿ç”¨**: æ¯å¤©æŠ“å–TOP5çƒ­ç‚¹ï¼Œç”Ÿæˆ3-5ç¯‡æ–‡ç« 
3. **è´¨é‡ä¼˜å…ˆ**: ä½¿ç”¨æ·±åº¦æœç´¢æ¨¡å¼ï¼ˆ`--search-depth deep`ï¼‰
4. **äººå·¥å®¡æ ¸**: ç”ŸæˆååŠ¡å¿…æ£€æŸ¥å†…å®¹å‡†ç¡®æ€§å’Œåˆè§„æ€§

## ğŸ“ æŠ€æœ¯æ”¯æŒ

å¦‚æœ‰é—®é¢˜ï¼Œè¯·æŸ¥çœ‹ï¼š
- é¡¹ç›®Issues
- è¿è¡Œæ—¥å¿—ï¼ˆ`data/generated/` ç›®å½•ï¼‰
- APIè°ƒç”¨æ—¥å¿—ï¼ˆdebugæ¨¡å¼ï¼‰

---

**Made with â¤ï¸ by posts-copilot Team**
